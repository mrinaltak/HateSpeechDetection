{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25QT54O2UjEh"
   },
   "source": [
    "Reference: https://github.com/dh1105/Sentence-Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9YGhQEYnj7DD",
    "outputId": "819c882f-b0a1-4459-c424-d46e5be61b4f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uqcn3_lQ5Hhr",
    "outputId": "480b8d47-49e8-407d-cbb0-de91efbd2a15"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "## !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JQ4M8Znd4_ep"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "# import torch_xla\n",
    "# import torch_xla.core.xla_model as xm\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WkpfPDS1Z8a8",
    "outputId": "f7f15058-4a5a-44b3-a978-36a6f499f710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-eyFJM1SstoH"
   },
   "outputs": [],
   "source": [
    "base_path = '/content/drive/MyDrive/COMPSCI 685 Advanced Natural Language Processing/Project/'\n",
    "task_a_hyp = \"This is offensive speech.\"\n",
    "task_b_hyp = \"This is targeted offense.\"\n",
    "task_c_hyp_1= \"This is targeted towards an individual.\"\n",
    "task_c_hyp_2 = \"This is targeted towards a group.\"\n",
    "task_c_hyp_3 = \"This isn't targeted towards a group or an individual.\"\n",
    "f = open(base_path + 'Data/OffensEval/olid_train_v2.csv')\n",
    "f_a = open(base_path + 'Data/OffensEval/bert_nli_train.csv', 'w')\n",
    "f_a.write('tweet_id' + '\\t' + 'gold_label' + '\\t' + 'sentence1' + '\\t' + 'sentence2' + '\\n')\n",
    "lines = f.readlines()\n",
    "for line in lines[1:]:\n",
    "  row = line.split('\\t')\n",
    "  tweet_id = row[0].strip()\n",
    "  tweet_text = ' '.join(row[1:-3]).strip()\n",
    "  is_offensive = row[-3].strip()\n",
    "  is_targeted = row[-2].strip()\n",
    "  target = row[-1].strip()\n",
    "  if is_offensive == 'OFF':\n",
    "    f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_a_hyp + '\\n')\n",
    "    if is_targeted == 'TIN':\n",
    "      f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_b_hyp + '\\n')\n",
    "      if target == 'IND':\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_c_hyp_1 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_2 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_3 + '\\n')\n",
    "      elif target == 'GRP':\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_1 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_c_hyp_2 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_3 + '\\n')\n",
    "      elif target == 'OTH':\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_1 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_2 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_c_hyp_3 + '\\n')\n",
    "    elif is_targeted == 'UNT':\n",
    "      f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_b_hyp + '\\n')\n",
    "  else:\n",
    "    f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_a_hyp + '\\n')\n",
    "f.close()\n",
    "f_a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a_hyp = \"This is offensive speech.\"\n",
    "task_b_hyp = \"This is targeted offense.\"\n",
    "task_c_hyp_1= \"This is targeted towards an individual.\"\n",
    "task_c_hyp_2 = \"This is targeted towards a group.\"\n",
    "task_c_hyp_3 = \"This isn't targeted towards a group or an individual.\"\n",
    "f = open(base_path + 'Data/OffensEval/olid_val_v2.csv')\n",
    "f_a = open(base_path + 'Data/OffensEval/bert_nli_val.csv', 'w')\n",
    "f_a.write('tweet_id' + '\\t' + 'gold_label' + '\\t' + 'sentence1' + '\\t' + 'sentence2' + '\\n')\n",
    "lines = f.readlines()\n",
    "for line in lines[1:]:\n",
    "  row = line.split('\\t')\n",
    "  tweet_id = row[0].strip()\n",
    "  tweet_text = ' '.join(row[1:-3]).strip()\n",
    "  is_offensive = row[-3].strip()\n",
    "  is_targeted = row[-2].strip()\n",
    "  target = row[-1].strip()\n",
    "  if is_offensive == 'OFF':\n",
    "    f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_a_hyp + '\\n')\n",
    "    if is_targeted == 'TIN':\n",
    "      f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_b_hyp + '\\n')\n",
    "      if target == 'IND':\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_c_hyp_1 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_2 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_3 + '\\n')\n",
    "      elif target == 'GRP':\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_1 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_c_hyp_2 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_3 + '\\n')\n",
    "      elif target == 'OTH':\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_1 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_2 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_c_hyp_3 + '\\n')\n",
    "    elif is_targeted == 'UNT':\n",
    "      f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_b_hyp + '\\n')\n",
    "  else:\n",
    "    f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_a_hyp + '\\n')\n",
    "f.close()\n",
    "f_a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = \"This is offensive speech.\"\n",
    "f = open(base_path + 'Data/OffensEval/olid_test_subtask_a.csv')\n",
    "f_a = open(base_path + 'Data/OffensEval/bert_nli_test_a.csv', 'w')\n",
    "f_a.write('tweet_id' + '\\t' + 'gold_label' + '\\t' + 'sentence1' + '\\t' + 'sentence2' + '\\n')\n",
    "for line in f.readlines()[1:]:\n",
    "    tweet_id, tweet_text, label = [x.strip() for x in line.split('\\t')]\n",
    "    if label == 'OFF':\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + hyp + '\\n')\n",
    "    else:\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + hyp + '\\n')\n",
    "f_a.close()\n",
    "f.close()\n",
    "hyp = \"This is targeted offense.\"\n",
    "f = open(base_path + 'Data/OffensEval/olid_test_subtask_b.csv')\n",
    "f_a = open(base_path + 'Data/OffensEval/bert_nli_test_b.csv', 'w')\n",
    "f_a.write('tweet_id' + '\\t' + 'gold_label' + '\\t' + 'sentence1' + '\\t' + 'sentence2' + '\\n')\n",
    "for line in f.readlines()[1:]:\n",
    "    tweet_id, tweet_text, label = [x.strip() for x in line.split('\\t')]\n",
    "    if label == 'TIN':\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + hyp + '\\n')\n",
    "    else:\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + hyp + '\\n')\n",
    "f_a.close()\n",
    "f.close()\n",
    "hyp_1= \"This is targeted towards an individual.\"\n",
    "hyp_2 = \"This is targeted towards a group.\"\n",
    "hyp_3 = \"This isn't targeted towards a group or an individual.\"\n",
    "f = open(base_path + 'Data/OffensEval/olid_test_subtask_c.csv')\n",
    "f_a = open(base_path + 'Data/OffensEval/bert_nli_test_c.csv', 'w')\n",
    "f_a.write('tweet_id' + '\\t' + 'gold_label' + '\\t' + 'sentence1' + '\\t' + 'sentence2' + '\\n')\n",
    "for line in f.readlines()[1:]:\n",
    "    tweet_id, tweet_text, label = [x.strip() for x in line.split('\\t')]\n",
    "    if label == 'IND':\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + hyp_1 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + hyp_2 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + hyp_3 + '\\n')\n",
    "    elif label == 'GRP':\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + hyp_1 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + hyp_2 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + hyp_3 + '\\n')\n",
    "    else:\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + hyp_1 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + hyp_2 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + hyp_3 + '\\n')\n",
    "f_a.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_a = pd.read_csv(base_path + 'Data/OffensEval/bert_nli_test_a.csv', delimiter='\\t')\n",
    "test_df_b = pd.read_csv(base_path + 'Data/OffensEval/bert_nli_test_b.csv', delimiter='\\t')\n",
    "test_df_c = pd.read_csv(base_path + 'Data/OffensEval/bert_nli_test_c.csv', delimiter='\\t')\n",
    "train_df = pd.read_csv(base_path + 'Data/OffensEval/bert_nli_train.csv', delimiter='\\t')\n",
    "val_df = pd.read_csv(base_path + 'Data/OffensEval/bert_nli_val.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "3NgPYXBg4_e7"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.dropna()\n",
    "val_df = val_df.dropna()\n",
    "test_df_a = test_df_a.dropna()\n",
    "test_df_b = test_df_b.dropna()\n",
    "test_df_c = test_df_c.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UMTQb1iMF54W"
   },
   "outputs": [],
   "source": [
    "train_df['sentence1'] = train_df['sentence1'].astype(str)\n",
    "train_df['sentence2'] = train_df['sentence2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GMzPNmtpF8yg"
   },
   "outputs": [],
   "source": [
    "val_df['sentence1'] = val_df['sentence1'].astype(str)\n",
    "val_df['sentence2'] = val_df['sentence2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6UBcmYsPzWA7"
   },
   "outputs": [],
   "source": [
    "test_df_a['sentence1'] = test_df_a['sentence1'].astype(str)\n",
    "test_df_a['sentence2'] = test_df_a['sentence2'].astype(str)\n",
    "test_df_b['sentence1'] = test_df_b['sentence1'].astype(str)\n",
    "test_df_b['sentence2'] = test_df_b['sentence2'].astype(str)\n",
    "test_df_c['sentence1'] = test_df_c['sentence1'].astype(str)\n",
    "test_df_c['sentence2'] = test_df_c['sentence2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "diS3wCm14_e9"
   },
   "outputs": [],
   "source": [
    "train_df = train_df[(train_df['sentence1'].str.split().str.len() > 0) & (train_df['sentence2'].str.split().str.len() > 0)]\n",
    "val_df = val_df[(val_df['sentence1'].str.split().str.len() > 0) & (val_df['sentence2'].str.split().str.len() > 0)]\n",
    "test_df_a = test_df_a[(test_df_a['sentence1'].str.split().str.len() > 0) & (test_df_a['sentence2'].str.split().str.len() > 0)]\n",
    "test_df_b = test_df_b[(test_df_b['sentence1'].str.split().str.len() > 0) & (test_df_b['sentence2'].str.split().str.len() > 0)]\n",
    "test_df_c = test_df_c[(test_df_c['sentence1'].str.split().str.len() > 0) & (test_df_c['sentence2'].str.split().str.len() > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "P11Q5BRkX70D"
   },
   "outputs": [],
   "source": [
    "test_df_a = test_df_a.sort_values(by=['tweet_id'])\n",
    "test_df_b = test_df_b.sort_values(by=['tweet_id'])\n",
    "temp = test_df_c.copy()\n",
    "test_df_c = temp[temp.sentence2 == \"This is targeted towards an individual.\"].sort_values(by=['tweet_id'])\n",
    "test_df_d = temp[temp.sentence2 == \"This is targeted towards a group.\"].sort_values(by=['tweet_id'])\n",
    "test_df_e = temp[temp.sentence2 == \"This isn't targeted towards a group or an individual.\"].sort_values(by=['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSjkMi9VZ4N2",
    "outputId": "5f824c54-3425-48d2-faa7-a7f85693565c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860\n",
      "860\n",
      "213\n",
      "213\n",
      "213\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df_a))\n",
    "print(len(test_df_b))\n",
    "print(len(test_df_c))\n",
    "print(len(test_df_d))\n",
    "print(len(test_df_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_df_a, test_df_b, test_df_c, test_df_d, test_df_e], axis=0, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Gk96lNh94_e_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pickle\n",
    "import os\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df, test_df_a, test_df_b, test_df_c, test_df_d, test_df_e):\n",
    "    self.label_dict = {'entailment': 1, 'contradiction': 0}\n",
    "\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "    self.test_df_a = test_df_a\n",
    "    self.test_df_b = test_df_b\n",
    "    self.test_df_c = test_df_c\n",
    "    self.test_df_d = test_df_d\n",
    "    self.test_df_e = test_df_e\n",
    "    self.base_path = base_path + 'mnli-data-offenseval'\n",
    "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.test_data_a = None\n",
    "    self.test_data_b = None\n",
    "    self.test_data_c = None\n",
    "    self.test_data_d = None\n",
    "    self.test_data_e = None\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    #Saving takes too much RAM\n",
    "    \n",
    "    if os.path.exists(os.path.join(self.base_path, 'train_data.pkl')):\n",
    "      print(\"Found training data\")\n",
    "      with open(os.path.join(self.base_path, 'train_data.pkl'), 'rb') as f:\n",
    "        self.train_data = pickle.load(f)\n",
    "    else:\n",
    "      self.train_data = self.load_data(self.train_df)\n",
    "      with open(os.path.join(self.base_path, 'train_data.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.train_data, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'val_data.pkl')):\n",
    "      print(\"Found val data\")\n",
    "      with open(os.path.join(self.base_path, 'val_data.pkl'), 'rb') as f:\n",
    "        self.val_data = pickle.load(f)\n",
    "    else:\n",
    "      self.val_data = self.load_data(self.val_df)\n",
    "      with open(os.path.join(self.base_path, 'val_data.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.val_data, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'test_data.pkl')):\n",
    "      print(\"Found test data\")\n",
    "      with open(os.path.join(self.base_path, 'test_data.pkl'), 'rb') as f:\n",
    "        self.test_data = pickle.load(f)\n",
    "    else:\n",
    "      self.test_data = self.load_data(self.test_df)\n",
    "      with open(os.path.join(self.base_path, 'test_data.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.test_data, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'test_data_a.pkl')):\n",
    "      print(\"Found test data a\")\n",
    "      with open(os.path.join(self.base_path, 'test_data_a.pkl'), 'rb') as f:\n",
    "        self.test_data_a = pickle.load(f)\n",
    "    else:\n",
    "      self.test_data_a = self.load_data(self.test_df_a)\n",
    "      with open(os.path.join(self.base_path, 'test_data_a.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.test_data_a, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'test_data_b.pkl')):\n",
    "      print(\"Found test data b\")\n",
    "      with open(os.path.join(self.base_path, 'test_data_b.pkl'), 'rb') as f:\n",
    "        self.test_data_b = pickle.load(f)\n",
    "    else:\n",
    "      self.test_data_b = self.load_data(self.test_df_b)\n",
    "      with open(os.path.join(self.base_path, 'test_data_b.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.test_data_b, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'test_data_c.pkl')):\n",
    "      print(\"Found test data c\")\n",
    "      with open(os.path.join(self.base_path, 'test_data_c.pkl'), 'rb') as f:\n",
    "        self.test_data_c = pickle.load(f)\n",
    "    else:\n",
    "      self.test_data_c = self.load_data(self.test_df_c)\n",
    "      with open(os.path.join(self.base_path, 'test_data_c.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.test_data_c, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'test_data_d.pkl')):\n",
    "      print(\"Found test data d\")\n",
    "      with open(os.path.join(self.base_path, 'test_data_d.pkl'), 'rb') as f:\n",
    "        self.test_data_d = pickle.load(f)\n",
    "    else:\n",
    "      self.test_data_d = self.load_data(self.test_df_d)\n",
    "      with open(os.path.join(self.base_path, 'test_data_d.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.test_data_d, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'test_data_e.pkl')):\n",
    "      print(\"Found test data e\")\n",
    "      with open(os.path.join(self.base_path, 'test_data_e.pkl'), 'rb') as f:\n",
    "        self.test_data_e = pickle.load(f)\n",
    "    else:\n",
    "      self.test_data_e = self.load_data(self.test_df_e)\n",
    "      with open(os.path.join(self.base_path, 'test_data_e.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.test_data_e, f)\n",
    "    # self.train_data = self.load_data(self.train_df)\n",
    "    # self.val_data = self.load_data(self.val_df)\n",
    "    # self.test_data = self.load_data(self.test_df)\n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512\n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "\n",
    "    premise_list = df['sentence1'].to_list()\n",
    "    hypothesis_list = df['sentence2'].to_list()\n",
    "    label_list = df['gold_label'].to_list()\n",
    "\n",
    "    for (premise, hypothesis, label) in zip(premise_list, hypothesis_list, label_list):\n",
    "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
    "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
    "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
    "      premise_len = len(premise_id)\n",
    "      hypothesis_len = len(hypothesis_id)\n",
    "\n",
    "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
    "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
    "\n",
    "      token_ids.append(torch.tensor(pair_token_ids))\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "    \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n",
    "    print(len(dataset))\n",
    "    return dataset\n",
    "\n",
    "  def get_data_loaders(self, batch_size=32, shuffle=True):\n",
    "    train_loader = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader_a = DataLoader(\n",
    "      self.test_data_a,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader_b = DataLoader(\n",
    "      self.test_data_b,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader_c = DataLoader(\n",
    "      self.test_data_c,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader_d = DataLoader(\n",
    "      self.test_data_d,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader_e = DataLoader(\n",
    "      self.test_data_e,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader, test_loader_a, test_loader_b, test_loader_c, test_loader_d, test_loader_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284,
     "referenced_widgets": [
      "6c0f5454779b4baeafa828e961459116",
      "f17b3761a665477e8fdecfd23d267f87",
      "a39de3d6df814e98be1a65e049bff39e",
      "ef706620a1e34c3a84de18a03a85f8cd",
      "bfee36d5b72d469cb308f4007e1474a0",
      "f3dea62699df437c945160dfc42afbd5",
      "24f1399337dc4cf998e189d697b8e282",
      "ff8facd357854c18976dea8f1621cae6",
      "e0c07e3c6bd042c2a3dd2aed325f6759",
      "4720c540eecc4dbe8fee8c9596f56933",
      "dcde074381814577a68122dd6e5adf30",
      "95d0e5c35a01408fa9bde956d0785d21",
      "93ded7574b56441eaa9b6aaaa30840f3",
      "405ea21b2692487298e89e719c6573b0",
      "0183e10141f049a1820827c9dfbd6c5a",
      "8665ae01129141dfb7fdf5037a994c86",
      "16b6fa8b34e24eedb7c6c80e9e57b5d2",
      "dd90fde29e26447c9eaeef9aaf15d01f",
      "8a4784a513b749d68959b4250a8a1593",
      "d01f56954ef74452b649def7b9adc937",
      "a61965e1ea50438c868778deb83db312",
      "93f0f8c7257944e6ab97295f09821f1d",
      "c38a9f17f85544b68ffdc8e501a95f20",
      "41fe1073e1ea44669cdbef98949f9528",
      "45dcdc23c9b4481a9e40878e4dbfd585",
      "322cc0d27aea4458a9efe1c099943482",
      "e4669478d1474c4485c45907447d75a5",
      "d09c0639c5ef45a7823074eb648de6d7",
      "f2a5689111c3420c9ed4114bb55cf0fc",
      "677cf9fc8f3d47c68e73bd4a3622132b",
      "e0d781c1aae342ae949264fb561b7f5f",
      "602d9b5979084873996eab9784b98edc",
      "546361d1061243f5b7fc5692b1c9d4c5",
      "30c1af9f395f4f148a4038c1f13b2088",
      "1543919f31dd46c6a967a412af4d21bd",
      "7e7c6e812fdc4b36a25096e9f176f75a",
      "bf7f2daca2264bd289670898d7ab10e4",
      "3af999385a094ccc85eadf702ab69723",
      "d84069b7b1384beaa5100505f9233b2b",
      "2e8aaf8e2a644b8384d07e86578e7624",
      "89a7fc4f932041a7b76b2502096ede49",
      "5d80c6db4dfc4bf0aaea82350dffdc21",
      "c2496080cc384158856247dd5581e751",
      "3e50074e3a054225842a6fe8ef936183"
     ]
    },
    "id": "md52P1z14_e_",
    "outputId": "e875db6f-6bb9-44a1-f2de-0e8cbea3e883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29268\n",
      "1914\n",
      "2165\n",
      "860\n",
      "240\n",
      "639\n",
      "213\n",
      "213\n"
     ]
    }
   ],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df, test_df_a, test_df_b, test_df_c, test_df_d, test_df_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "-LSyABLG4_fA"
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, test_loader_a, test_loader_b, test_loader_c, test_loader_d, test_loader_e = mnli_dataset.get_data_loaders(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e8a66bb5d7614602ac93db9cac811135",
      "0504a8ce7be543a49611a424fcfc9ca7",
      "bf065a9136dc4262a74c04f746b7c143",
      "6f61782328964e4dbdea05bee3797ee9",
      "814534237a9144deb7d52e4ceffabc43",
      "43f942f812884ace90aa9b1dd41a3d9a",
      "9d383d03f9304bce914326ea0e5d472b",
      "6b127ca5fb5a4d23b6c3ffe654cdfcaf",
      "fb792d8fbadc4bb6977a1986a9783e15",
      "373af73466be45f1bb216e6abbdb15be",
      "6497737147ce458b881bbb1b17492364"
     ]
    },
    "id": "qOdc4Cs2DEjt",
    "outputId": "7cdbd55e-a6e6-4cad-e765-de1a18e3f0c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jxzpENXlEh-u"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "is1TqwTREid9"
   },
   "outputs": [],
   "source": [
    "# This variable contains all of the hyperparemeter information our training loop needs\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79aI1dun4_fB",
    "outputId": "eb5cbe4e-f9fa-4618-d840-611d259037f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 109,483,778 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qhU855Cw4_fB"
   },
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "OfhYO7Db4_fB"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer):  \n",
    "  total_step = len(train_loader)\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
    "      optimizer.zero_grad()\n",
    "      if batch_idx%100 == 0:\n",
    "          print(batch_idx, len(train_loader))\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "\n",
    "      # loss = criterion(prediction, labels)\n",
    "      acc = multi_acc(prediction, labels)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "    model.eval()\n",
    "    total_val_acc  = 0\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "      for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(val_loader):\n",
    "        optimizer.zero_grad()\n",
    "        pair_token_ids = pair_token_ids.to(device)\n",
    "        mask_ids = mask_ids.to(device)\n",
    "        seg_ids = seg_ids.to(device)\n",
    "        labels = y.to(device)\n",
    "\n",
    "        # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "        loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "        \n",
    "        # loss = criterion(prediction, labels)\n",
    "        acc = multi_acc(prediction, labels)\n",
    "\n",
    "        total_val_loss += loss.item()\n",
    "        total_val_acc  += acc.item()\n",
    "\n",
    "    val_acc  = total_val_acc/len(val_loader)\n",
    "    val_loss = total_val_loss/len(val_loader)\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    torch.save(model.state_dict(),os.path.join(base_path + 'WeightsOffenseval', 'nli_{}.pt'.format(epoch)))\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "TisZ5o86nkMW"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "def test(model, test_loader):\n",
    "  model.load_state_dict(torch.load(base_path+'WeightsOffenseval/nli_3.pt', map_location=torch.device('cpu')))\n",
    "  model.eval()\n",
    "  total_test_acc  = 0\n",
    "  total_test_loss = 0\n",
    "  start = time.time()\n",
    "  preds = []\n",
    "  acts = []\n",
    "  with torch.no_grad():\n",
    "    #print(\"Prediction\", \"Label\")\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(test_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "\n",
    "      # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                           token_type_ids=seg_ids, \n",
    "                           attention_mask=mask_ids, \n",
    "                           labels=labels).values()\n",
    "        \n",
    "      # loss = criterion(prediction, labels)\n",
    "      acc = multi_acc(prediction, labels)\n",
    "      preds = preds + prediction.tolist()\n",
    "      acts = acts + labels.tolist()\n",
    "      #print(prediction, labels)\n",
    "      total_test_loss += loss.item()\n",
    "      total_test_acc  += acc.item() \n",
    "\n",
    "  test_acc  = total_test_acc/len(test_loader)\n",
    "  test_loss = total_test_loss/len(test_loader)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "  print(f'test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  #return [math.exp(preds[i][1])/(math.exp(preds[i][0] + math.exp(preds[i][1]))) for i in range(len(preds))], acts\n",
    "  #return [0 if preds[i][0] > preds[i][1] else 1 for i in range(len(preds))], acts\n",
    "  return preds, acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPIxT4RB4_fC",
    "outputId": "9af2f2cb-4099-4673-f834-18bcc9bfcac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 458\n",
      "100 458\n",
      "200 458\n",
      "300 458\n",
      "400 458\n",
      "Epoch 1: train_loss: 0.2690 train_acc: 0.8965 | val_loss: 0.1696 val_acc: 0.9390\n",
      "00:12:51.07\n",
      "0 458\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29398/1576668980.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_29398/1192915613.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, optimizer)\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/scratch1/nikhilagarwa/anaconda3/envs/nikhil/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/scratch1/nikhilagarwa/anaconda3/envs/nikhil/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "3nGBLgp312AD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.4694 test_acc: 0.7990\n",
      "00:00:11.02\n"
     ]
    }
   ],
   "source": [
    "preds, acts = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5w11ZMTvp6yr",
    "outputId": "879fa89b-bfca-4b6e-a749-d77eb8239ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.4511 test_acc: 0.8139\n",
      "00:00:04.18\n"
     ]
    }
   ],
   "source": [
    "preds_a, acts_a = test(model, test_loader_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 189, FP: 108\n",
      "FN: 51, TN: 512\n",
      "Recall: 0.7875\n",
      "Precsion: 0.6363636363636364\n",
      "F1: 0.7039106145251396\n",
      "Accuracy 0.8151162790697675\n"
     ]
    }
   ],
   "source": [
    "#CLASS A:\n",
    "tp_a = 0\n",
    "fp_a = 0\n",
    "tn_a = 0\n",
    "fn_a = 0\n",
    "preds_a = [math.exp(preds_a[i][1])/(math.exp(preds_a[i][0]) + math.exp(preds_a[i][1])) for i in range(len(preds_a))]\n",
    "for i in range(len(preds_a)):\n",
    "    if acts_a[i] == 1:\n",
    "        if preds_a[i] >= 0.5:\n",
    "            tp_a += 1\n",
    "        else:\n",
    "            fn_a += 1\n",
    "    else:\n",
    "        if preds_a[i] < 0.5:\n",
    "            tn_a += 1\n",
    "        else:\n",
    "            fp_a += 1\n",
    "accuracy_a = (tp_a + tn_a)/(tp_a + fp_a + fn_a + tn_a)\n",
    "recall_a = tp_a/(tp_a + fn_a)\n",
    "precision_a = tp_a/(tp_a + fp_a)\n",
    "f1_a = (2*precision_a*recall_a)/(precision_a + recall_a)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_a, fp_a, fn_a, tn_a))\n",
    "print(\"Recall:\", recall_a)\n",
    "print(\"Precsion:\", precision_a)\n",
    "print(\"F1:\", f1_a)\n",
    "print(\"Accuracy\", accuracy_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total offensive examples: 240\n",
      "Correctly predicted offensive examples: 189\n",
      "Accuracy for predicting offensive examples: 0.7875\n",
      "Total non offensive examples: 620\n",
      "Correctly predicted non offensive examples: 512\n",
      "Accuracy for predicting non offensive examples: 0.8258064516129032\n"
     ]
    }
   ],
   "source": [
    "ent_acts_a = 0\n",
    "cont_acts_a = 0\n",
    "correct_ents_a = 0\n",
    "correct_conts_a = 0\n",
    "for i in range(len(preds_a)):\n",
    "    if acts_a[i] == 1:\n",
    "        ent_acts_a += 1\n",
    "        if preds_a[i] >= 0.5:\n",
    "            correct_ents_a += 1\n",
    "    else:\n",
    "        cont_acts_a += 1\n",
    "        if preds_a[i] < 0.5:\n",
    "            correct_conts_a += 1\n",
    "            \n",
    "print(\"Total offensive examples:\", ent_acts_a)\n",
    "print(\"Correctly predicted offensive examples:\", correct_ents_a)\n",
    "print(\"Accuracy for predicting offensive examples:\", correct_ents_a/ent_acts_a)\n",
    "print(\"Total non offensive examples:\", cont_acts_a)\n",
    "print(\"Correctly predicted non offensive examples:\", correct_conts_a)\n",
    "print(\"Accuracy for predicting non offensive examples:\", correct_conts_a/cont_acts_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "uqIU3lTPqLkV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.2992 test_acc: 0.8854\n",
      "00:00:01.16\n"
     ]
    }
   ],
   "source": [
    "preds_b, acts_b = test(model, test_loader_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 203, FP: 17\n",
      "FN: 10, TN: 10\n",
      "Recall: 0.9530516431924883\n",
      "Precsion: 0.9227272727272727\n",
      "F1: 0.9376443418013857\n",
      "Accuracy 0.8875\n"
     ]
    }
   ],
   "source": [
    "#CLASS B:\n",
    "tp_b = 0\n",
    "fp_b = 0\n",
    "tn_b = 0\n",
    "fn_b = 0\n",
    "preds_b = [math.exp(preds_b[i][1])/(math.exp(preds_b[i][0]) + math.exp(preds_b[i][1])) for i in range(len(preds_b))]\n",
    "for i in range(len(preds_b)):\n",
    "    if acts_b[i] == 1:\n",
    "        if preds_b[i] >= 0.5:\n",
    "            tp_b += 1\n",
    "        else:\n",
    "            fn_b += 1\n",
    "    else:\n",
    "        if preds_b[i] < 0.5:\n",
    "            tn_b += 1\n",
    "        else:\n",
    "            fp_b += 1\n",
    "accuracy_b = (tp_b + tn_b)/(tp_b + fp_b + fn_b + tn_b)\n",
    "recall_b = tp_b/(tp_b + fn_b)\n",
    "precision_b = tp_b/(tp_b + fp_b)\n",
    "f1_b = (2*precision_b*recall_b)/(precision_b + recall_b)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_b, fp_b, fn_b, tn_b))\n",
    "print(\"Recall:\", recall_b)\n",
    "print(\"Precsion:\", precision_b)\n",
    "print(\"F1:\", f1_b)\n",
    "print(\"Accuracy\", accuracy_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total targeted offensive examples: 240\n",
      "Correctly predicted targeted offensive examples: 189\n",
      "Accuracy for predicting targeted offensive examples: 0.7875\n",
      "Total non targeted offensive examples: 620\n",
      "Correctly predicted non targeted offensive examples: 512\n",
      "Accuracy for predicting non targeted offensive examples: 0.8258064516129032\n"
     ]
    }
   ],
   "source": [
    "ent_acts_b = 0\n",
    "cont_acts_b = 0\n",
    "correct_ents_b = 0\n",
    "correct_conts_b = 0\n",
    "for i in range(len(preds_b)):\n",
    "    if acts_b[i] == 1:\n",
    "        ent_acts_b += 1\n",
    "        if preds_b[i] > 0.5:\n",
    "            correct_ents_b += 1\n",
    "    else:\n",
    "        cont_acts_b += 1\n",
    "        if preds_b[i] < 0.5:\n",
    "            correct_conts_b += 1\n",
    "            \n",
    "print(\"Total targeted offensive examples:\", ent_acts_b)\n",
    "print(\"Correctly predicted targeted offensive examples:\", correct_ents_b)\n",
    "print(\"Accuracy for predicting targeted offensive examples:\", correct_ents_b/ent_acts_b)\n",
    "print(\"Total non targeted offensive examples:\", cont_acts_b)\n",
    "print(\"Correctly predicted non targeted offensive examples:\", correct_conts_b)\n",
    "print(\"Accuracy for predicting non targeted offensive examples:\", correct_conts_b/cont_acts_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8TyO6pUpqk1i",
    "outputId": "a1fa4716-4858-4ede-b8f5-89828ca0d40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5668 test_acc: 0.8080\n",
      "00:00:01.07\n"
     ]
    }
   ],
   "source": [
    "preds_c, acts_c = test(model, test_loader_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 79, FP: 22\n",
      "FN: 21, TN: 91\n",
      "Recall: 0.79\n",
      "Precsion: 0.7821782178217822\n",
      "F1: 0.7860696517412936\n",
      "Accuracy 0.7981220657276995\n"
     ]
    }
   ],
   "source": [
    "#CLASS C:\n",
    "tp_c = 0\n",
    "fp_c = 0\n",
    "tn_c = 0\n",
    "fn_c = 0\n",
    "preds_c = [math.exp(preds_c[i][1])/(math.exp(preds_c[i][0]) + math.exp(preds_c[i][1])) for i in range(len(preds_c))]\n",
    "for i in range(len(preds_c)):\n",
    "    if acts_c[i] == 1:\n",
    "        if preds_c[i] >= 0.5:\n",
    "            tp_c += 1\n",
    "        else:\n",
    "            fn_c += 1\n",
    "    else:\n",
    "        if preds_c[i] < 0.5:\n",
    "            tn_c += 1\n",
    "        else:\n",
    "            fp_c += 1\n",
    "accuracy_c = (tp_c + tn_c)/(tp_c + fp_c + fn_c + tn_c)\n",
    "recall_c = tp_c/(tp_c + fn_c)\n",
    "precision_c = tp_c/(tp_c + fp_c)\n",
    "f1_c = (2*precision_c*recall_c)/(precision_c + recall_c)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_c, fp_c, fn_c, tn_c))\n",
    "print(\"Recall:\", recall_c)\n",
    "print(\"Precsion:\", precision_c)\n",
    "print(\"F1:\", f1_c)\n",
    "print(\"Accuracy\", accuracy_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total individual targeted offensive examples: 100\n",
      "Correctly predicted individual targeted offensive examples: 79\n",
      "Accuracy for predicting individual targeted offensive examples: 0.79\n",
      "Total non individual targeted offensive examples: 113\n",
      "Correctly predicted non individual targeted offensive examples: 113\n",
      "Accuracy for predicting non individual targeted offensive examples: 1.0\n"
     ]
    }
   ],
   "source": [
    "ent_acts_c = 0\n",
    "cont_acts_c = 0\n",
    "correct_ents_c = 0\n",
    "correct_conts_c = 0\n",
    "for i in range(len(preds_c)):\n",
    "    if acts_c[i] == 1:\n",
    "        ent_acts_c += 1\n",
    "        if preds_c[i] >= 0.5:\n",
    "            correct_ents_c += 1\n",
    "    else:\n",
    "        cont_acts_c += 1\n",
    "        if preds_c[i] < 1:\n",
    "            correct_conts_c += 1\n",
    "            \n",
    "print(\"Total individual targeted offensive examples:\", ent_acts_c)\n",
    "print(\"Correctly predicted individual targeted offensive examples:\", correct_ents_c)\n",
    "print(\"Accuracy for predicting individual targeted offensive examples:\", correct_ents_c/ent_acts_c)\n",
    "print(\"Total non individual targeted offensive examples:\", cont_acts_c)\n",
    "print(\"Correctly predicted non individual targeted offensive examples:\", correct_conts_c)\n",
    "print(\"Accuracy for predicting non individual targeted offensive examples:\", correct_conts_c/cont_acts_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZOu6kmwq9MM",
    "outputId": "8e8af0bb-8565-44fc-e2e6-1ecac75c810b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5722 test_acc: 0.7329\n",
      "00:00:01.09\n"
     ]
    }
   ],
   "source": [
    "preds_d, acts_d = test(model, test_loader_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 49, FP: 23\n",
      "FN: 29, TN: 112\n",
      "Recall: 0.6282051282051282\n",
      "Precsion: 0.6805555555555556\n",
      "F1: 0.6533333333333333\n",
      "Accuracy 0.755868544600939\n"
     ]
    }
   ],
   "source": [
    "#CLASS D:\n",
    "tp_d = 0\n",
    "fp_d = 0\n",
    "tn_d = 0\n",
    "fn_d = 0\n",
    "preds_d = [math.exp(preds_d[i][1])/(math.exp(preds_d[i][0]) + math.exp(preds_d[i][1])) for i in range(len(preds_d))]\n",
    "for i in range(len(preds_d)):\n",
    "    if acts_d[i] == 1:\n",
    "        if preds_d[i] >= 0.5:\n",
    "            tp_d += 1\n",
    "        else:\n",
    "            fn_d += 1\n",
    "    else:\n",
    "        if preds_d[i] < 0.5:\n",
    "            tn_d += 1\n",
    "        else:\n",
    "            fp_d += 1\n",
    "accuracy_d = (tp_d + tn_d)/(tp_d + fp_d + fn_d + tn_d)\n",
    "recall_d = tp_d/(tp_d + fn_d)\n",
    "precision_d = tp_d/(tp_d + fp_d)\n",
    "f1_d = (2*precision_d*recall_d)/(precision_d + recall_d)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_d, fp_d, fn_d, tn_d))\n",
    "print(\"Recall:\", recall_d)\n",
    "print(\"Precsion:\", precision_d)\n",
    "print(\"F1:\", f1_d)\n",
    "print(\"Accuracy\", accuracy_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total group targeted offensive examples: 78\n",
      "Correctly predicted group targeted offensive examples: 49\n",
      "Accuracy for predicting group targeted offensive examples: 0.6282051282051282\n",
      "Total non group targeted offensive examples: 135\n",
      "Correctly predicted non group targeted offensive examples: 112\n",
      "Accuracy for predicting non group targeted offensive examples: 0.8296296296296296\n"
     ]
    }
   ],
   "source": [
    "ent_acts_d = 0\n",
    "cont_acts_d = 0\n",
    "correct_ents_d = 0\n",
    "correct_conts_d = 0\n",
    "for i in range(len(preds_d)):\n",
    "    if acts_d[i] == 1:\n",
    "        ent_acts_d += 1\n",
    "        if preds_d[i] >= 0.5:\n",
    "            correct_ents_d += 1\n",
    "    else:\n",
    "        cont_acts_d += 1\n",
    "        if preds_d[i] < 0.5:\n",
    "            correct_conts_d += 1\n",
    "            \n",
    "print(\"Total group targeted offensive examples:\", ent_acts_d)\n",
    "print(\"Correctly predicted group targeted offensive examples:\", correct_ents_d)\n",
    "print(\"Accuracy for predicting group targeted offensive examples:\", correct_ents_d/ent_acts_d)\n",
    "print(\"Total non group targeted offensive examples:\", cont_acts_d)\n",
    "print(\"Correctly predicted non group targeted offensive examples:\", correct_conts_d)\n",
    "print(\"Accuracy for predicting non group targeted offensive examples:\", correct_conts_d/cont_acts_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUU1YuTIq_z3",
    "outputId": "b76f41c6-8267-4187-b31b-cd49df2c4f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.4725 test_acc: 0.7608\n",
      "00:00:01.09\n"
     ]
    }
   ],
   "source": [
    "preds_e, acts_e = test(model, test_loader_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 8, FP: 24\n",
      "FN: 27, TN: 154\n",
      "Recall: 0.22857142857142856\n",
      "Precsion: 0.25\n",
      "F1: 0.23880597014925375\n",
      "Accuracy 0.7605633802816901\n"
     ]
    }
   ],
   "source": [
    "#CLASS E:\n",
    "tp_e = 0\n",
    "fp_e = 0\n",
    "tn_e = 0\n",
    "fn_e = 0\n",
    "preds_e = [math.exp(preds_e[i][1])/(math.exp(preds_e[i][0]) + math.exp(preds_e[i][1])) for i in range(len(preds_e))]\n",
    "for i in range(len(preds_e)):\n",
    "    if acts_e[i] == 1:\n",
    "        if preds_e[i] >= 0.5:\n",
    "            tp_e += 1\n",
    "        else:\n",
    "            fn_e += 1\n",
    "    else:\n",
    "        if preds_e[i] < 0.5:\n",
    "            tn_e += 1\n",
    "        else:\n",
    "            fp_e += 1\n",
    "accuracy_e = (tp_e + tn_e)/(tp_e + fp_e + fn_e + tn_e)\n",
    "recall_e = tp_e/(tp_e + fn_e)\n",
    "precision_e = tp_e/(tp_e + fp_e)\n",
    "f1_e = (2*precision_e*recall_e)/(precision_e + recall_e)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_e, fp_e, fn_e, tn_e))\n",
    "print(\"Recall:\", recall_e)\n",
    "print(\"Precsion:\", precision_e)\n",
    "print(\"F1:\", f1_e)\n",
    "print(\"Accuracy\", accuracy_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total other targeted offensive examples: 35\n",
      "Correctly predicted other targeted offensive examples: 8\n",
      "Accuracy for predicting other targeted offensive examples: 0.22857142857142856\n",
      "Total non other targeted offensive examples: 178\n",
      "Correctly predicted non other targeted offensive examples: 154\n",
      "Accuracy for predicting non other targeted offensive examples: 0.8651685393258427\n"
     ]
    }
   ],
   "source": [
    "ent_acts_e = 0\n",
    "cont_acts_e = 0\n",
    "correct_ents_e = 0\n",
    "correct_conts_e = 0\n",
    "for i in range(len(preds_e)):\n",
    "    if acts_e[i] == 1:\n",
    "        ent_acts_e += 1\n",
    "        if preds_e[i] >= 0.5:\n",
    "            correct_ents_e += 1\n",
    "    else:\n",
    "        cont_acts_e += 1\n",
    "        if preds_e[i] < 0.5:\n",
    "            correct_conts_e += 1\n",
    "            \n",
    "print(\"Total other targeted offensive examples:\", ent_acts_e)\n",
    "print(\"Correctly predicted other targeted offensive examples:\", correct_ents_e)\n",
    "print(\"Accuracy for predicting other targeted offensive examples:\", correct_ents_e/ent_acts_e)\n",
    "print(\"Total non other targeted offensive examples:\", cont_acts_e)\n",
    "print(\"Correctly predicted non other targeted offensive examples:\", correct_conts_e)\n",
    "print(\"Accuracy for predicting non other targeted offensive examples:\", correct_conts_e/cont_acts_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro average F1 for class 3 IND/GRP/OTH is 0.5594029850746269\n",
      "Macro average F1 overall 0.7336526471337175\n"
     ]
    }
   ],
   "source": [
    "f1_3 = (f1_c + f1_d + f1_e)/3\n",
    "print(\"Macro average F1 for class 3 IND/GRP/OTH is\", f1_3)\n",
    "print(\"Macro average F1 overall\", (f1_a + f1_b + f1_3)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transfer(model, test_loader):\n",
    "  model.load_state_dict(torch.load(base_path + 'WeightsHateval/nli_new_4.pt', map_location=torch.device('cpu')))\n",
    "  model.eval()\n",
    "  total_test_acc  = 0\n",
    "  total_test_loss = 0\n",
    "  start = time.time()\n",
    "  preds = []\n",
    "  acts = []\n",
    "  with torch.no_grad():\n",
    "    #print(\"Prediction\", \"Label\")\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(test_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "\n",
    "      # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                           token_type_ids=seg_ids, \n",
    "                           attention_mask=mask_ids, \n",
    "                           labels=labels).values()\n",
    "        \n",
    "      # loss = criterion(prediction, labels)\n",
    "      acc = multi_acc(prediction, labels)\n",
    "      preds = preds + prediction.tolist()\n",
    "      acts = acts + labels.tolist()\n",
    "      #print(prediction, labels)\n",
    "      total_test_loss += loss.item()\n",
    "      total_test_acc  += acc.item() \n",
    "\n",
    "  test_acc  = total_test_acc/len(test_loader)\n",
    "  test_loss = total_test_loss/len(test_loader)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "  print(f'test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  return preds, acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.5004 test_acc: 0.6481\n",
      "00:00:04.15\n"
     ]
    }
   ],
   "source": [
    "preds_a_transfer, acts_a_transfer = test_transfer(model, test_loader_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 3.1208 test_acc: 0.3333\n",
      "00:00:01.17\n"
     ]
    }
   ],
   "source": [
    "preds_b_transfer, acts_b_transfer = test_transfer(model, test_loader_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.2519 test_acc: 0.6665\n",
      "00:00:01.06\n"
     ]
    }
   ],
   "source": [
    "preds_c_transfer, acts_c_transfer = test_transfer(model, test_loader_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 2.4865 test_acc: 0.4115\n",
      "00:00:01.06\n"
     ]
    }
   ],
   "source": [
    "preds_d_transfer, acts_d_transfer = test_transfer(model, test_loader_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.5778 test_acc: 0.5917\n",
      "00:00:01.10\n"
     ]
    }
   ],
   "source": [
    "preds_e_transfer, acts_e_transfer = test_transfer(model, test_loader_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 20, FP: 32\n",
      "FN: 42, TN: 119\n",
      "Recall: 0.3225806451612903\n",
      "Precsion: 0.38461538461538464\n",
      "F1: 0.3508771929824561\n",
      "Accuracy 0.6525821596244131\n"
     ]
    }
   ],
   "source": [
    "#CLASS A: Transfer learning from hateval\n",
    "\n",
    "tp_a_transfer = 0\n",
    "fp_a_transfer = 0\n",
    "tn_a_transfer = 0\n",
    "fn_a_transfer = 0\n",
    "preds_a_transfer = [math.exp(preds_a_transfer[i][1])/(math.exp(preds_a_transfer[i][0]) + math.exp(preds_a_transfer[i][1])) for i in range(len(preds_e))]\n",
    "for i in range(len(preds_a_transfer)):\n",
    "    if acts_a_transfer[i] == 1:\n",
    "        if preds_a_transfer[i] >= 0.5:\n",
    "            tp_a_transfer += 1\n",
    "        else:\n",
    "            fn_a_transfer += 1\n",
    "    else:\n",
    "        if preds_a_transfer[i] < 0.5:\n",
    "            tn_a_transfer += 1\n",
    "        else:\n",
    "            fp_a_transfer += 1\n",
    "accuracy_a_transfer = (tp_a_transfer + tn_a_transfer)/(tp_a_transfer + fp_a_transfer + fn_a_transfer + tn_a_transfer)\n",
    "recall_a_transfer = tp_a_transfer/(tp_a_transfer + fn_a_transfer)\n",
    "precision_a_transfer = tp_a_transfer/(tp_a_transfer + fp_a_transfer)\n",
    "f1_a_transfer = (2*precision_a_transfer*recall_a_transfer)/(precision_a_transfer + recall_a_transfer)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_a_transfer, fp_a_transfer, fn_a_transfer, tn_a_transfer))\n",
    "print(\"Recall:\", recall_a_transfer)\n",
    "print(\"Precsion:\", precision_a_transfer)\n",
    "print(\"F1:\", f1_a_transfer)\n",
    "print(\"Accuracy\", accuracy_a_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 55, FP: 9\n",
      "FN: 136, TN: 13\n",
      "Recall: 0.2879581151832461\n",
      "Precsion: 0.859375\n",
      "F1: 0.4313725490196078\n",
      "Accuracy 0.3192488262910798\n"
     ]
    }
   ],
   "source": [
    "#CLASS B: Transfer learning from hateval\n",
    "\n",
    "tp_b_transfer = 0\n",
    "fp_b_transfer = 0\n",
    "tn_b_transfer = 0\n",
    "fn_b_transfer = 0\n",
    "preds_b_transfer = [math.exp(preds_b_transfer[i][1])/(math.exp(preds_b_transfer[i][0]) + math.exp(preds_b_transfer[i][1])) for i in range(len(preds_e))]\n",
    "for i in range(len(preds_b_transfer)):\n",
    "    if acts_b_transfer[i] == 1:\n",
    "        if preds_b_transfer[i] >= 0.5:\n",
    "            tp_b_transfer += 1\n",
    "        else:\n",
    "            fn_b_transfer += 1\n",
    "    else:\n",
    "        if preds_b_transfer[i] < 0.5:\n",
    "            tn_b_transfer += 1\n",
    "        else:\n",
    "            fp_b_transfer += 1\n",
    "accuracy_b_transfer = (tp_b_transfer + tn_b_transfer)/(tp_b_transfer + fp_b_transfer + fn_b_transfer + tn_b_transfer)\n",
    "recall_b_transfer = tp_b_transfer/(tp_b_transfer + fn_b_transfer)\n",
    "precision_b_transfer = tp_b_transfer/(tp_b_transfer + fp_b_transfer)\n",
    "f1_b_transfer = (2*precision_b_transfer*recall_b_transfer)/(precision_b_transfer + recall_b_transfer)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_b_transfer, fp_b_transfer, fn_b_transfer, tn_b_transfer))\n",
    "print(\"Recall:\", recall_b_transfer)\n",
    "print(\"Precsion:\", precision_b_transfer)\n",
    "print(\"F1:\", f1_b_transfer)\n",
    "print(\"Accuracy\", accuracy_b_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 42, FP: 11\n",
      "FN: 58, TN: 102\n",
      "Recall: 0.42\n",
      "Precsion: 0.7924528301886793\n",
      "F1: 0.5490196078431373\n",
      "Accuracy 0.676056338028169\n"
     ]
    }
   ],
   "source": [
    "#CLASS C: Transfer learning from hateval\n",
    "\n",
    "tp_c_transfer = 0\n",
    "fp_c_transfer = 0\n",
    "tn_c_transfer = 0\n",
    "fn_c_transfer = 0\n",
    "preds_c_transfer = [math.exp(preds_c_transfer[i][1])/(math.exp(preds_c_transfer[i][0]) + math.exp(preds_c_transfer[i][1])) for i in range(len(preds_e))]\n",
    "for i in range(len(preds_c_transfer)):\n",
    "    if acts_c_transfer[i] == 1:\n",
    "        if preds_c_transfer[i] >= 0.5:\n",
    "            tp_c_transfer += 1\n",
    "        else:\n",
    "            fn_c_transfer += 1\n",
    "    else:\n",
    "        if preds_c_transfer[i] < 0.5:\n",
    "            tn_c_transfer += 1\n",
    "        else:\n",
    "            fp_c_transfer += 1\n",
    "accuracy_c_transfer = (tp_c_transfer + tn_c_transfer)/(tp_c_transfer + fp_c_transfer + fn_c_transfer + tn_c_transfer)\n",
    "recall_c_transfer = tp_c_transfer/(tp_c_transfer + fn_c_transfer)\n",
    "precision_c_transfer = tp_c_transfer/(tp_c_transfer + fp_c_transfer)\n",
    "f1_c_transfer = (2*precision_c_transfer*recall_c_transfer)/(precision_c_transfer + recall_c_transfer)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_c_transfer, fp_c_transfer, fn_c_transfer, tn_c_transfer))\n",
    "print(\"Recall:\", recall_c_transfer)\n",
    "print(\"Precsion:\", precision_c_transfer)\n",
    "print(\"F1:\", f1_c_transfer)\n",
    "print(\"Accuracy\", accuracy_c_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 6, FP: 50\n",
      "FN: 72, TN: 85\n",
      "Recall: 0.07692307692307693\n",
      "Precsion: 0.10714285714285714\n",
      "F1: 0.08955223880597014\n",
      "Accuracy 0.4272300469483568\n"
     ]
    }
   ],
   "source": [
    "#CLASS D: Transfer learning from hateval\n",
    "\n",
    "tp_d_transfer = 0\n",
    "fp_d_transfer = 0\n",
    "tn_d_transfer = 0\n",
    "fn_d_transfer = 0\n",
    "preds_d_transfer = [math.exp(preds_d_transfer[i][1])/(math.exp(preds_d_transfer[i][0]) + math.exp(preds_d_transfer[i][1])) for i in range(len(preds_e))]\n",
    "for i in range(len(preds_d_transfer)):\n",
    "    if acts_d_transfer[i] == 1:\n",
    "        if preds_d_transfer[i] >= 0.5:\n",
    "            tp_d_transfer += 1\n",
    "        else:\n",
    "            fn_d_transfer += 1\n",
    "    else:\n",
    "        if preds_d_transfer[i] < 0.5:\n",
    "            tn_d_transfer += 1\n",
    "        else:\n",
    "            fp_d_transfer += 1\n",
    "accuracy_d_transfer = (tp_d_transfer + tn_d_transfer)/(tp_d_transfer + fp_d_transfer + fn_d_transfer + tn_d_transfer)\n",
    "recall_d_transfer = tp_d_transfer/(tp_d_transfer + fn_d_transfer)\n",
    "precision_d_transfer = tp_d_transfer/(tp_d_transfer + fp_d_transfer)\n",
    "f1_d_transfer = (2*precision_d_transfer*recall_d_transfer)/(precision_d_transfer + recall_d_transfer)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_d_transfer, fp_d_transfer, fn_d_transfer, tn_d_transfer))\n",
    "print(\"Recall:\", recall_d_transfer)\n",
    "print(\"Precsion:\", precision_d_transfer)\n",
    "print(\"F1:\", f1_d_transfer)\n",
    "print(\"Accuracy\", accuracy_d_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 4, FP: 51\n",
      "FN: 31, TN: 127\n",
      "Recall: 0.11428571428571428\n",
      "Precsion: 0.07272727272727272\n",
      "F1: 0.08888888888888889\n",
      "Accuracy 0.6150234741784038\n"
     ]
    }
   ],
   "source": [
    "#CLASS D: Transfer learning from hateval\n",
    "\n",
    "tp_e_transfer = 0\n",
    "fp_e_transfer = 0\n",
    "tn_e_transfer = 0\n",
    "fn_e_transfer = 0\n",
    "preds_e_transfer = [math.exp(preds_e_transfer[i][1])/(math.exp(preds_e_transfer[i][0]) + math.exp(preds_e_transfer[i][1])) for i in range(len(preds_e))]\n",
    "for i in range(len(preds_e_transfer)):\n",
    "    if acts_e_transfer[i] == 1:\n",
    "        if preds_e_transfer[i] >= 0.5:\n",
    "            tp_e_transfer += 1\n",
    "        else:\n",
    "            fn_e_transfer += 1\n",
    "    else:\n",
    "        if preds_e_transfer[i] < 0.5:\n",
    "            tn_e_transfer += 1\n",
    "        else:\n",
    "            fp_e_transfer += 1\n",
    "accuracy_e_transfer = (tp_e_transfer + tn_e_transfer)/(tp_e_transfer + fp_e_transfer + fn_e_transfer + tn_e_transfer)\n",
    "recall_e_transfer = tp_e_transfer/(tp_e_transfer + fn_e_transfer)\n",
    "precision_e_transfer = tp_e_transfer/(tp_e_transfer + fp_e_transfer)\n",
    "f1_e_transfer = (2*precision_e_transfer*recall_e_transfer)/(precision_e_transfer + recall_e_transfer)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_e_transfer, fp_e_transfer, fn_e_transfer, tn_e_transfer))\n",
    "print(\"Recall:\", recall_e_transfer)\n",
    "print(\"Precsion:\", precision_e_transfer)\n",
    "print(\"F1:\", f1_e_transfer)\n",
    "print(\"Accuracy\", accuracy_e_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro average F1 for class 3 IND/GRP/OTH is 0.2424869118459988\n",
      "Macro average F1 overall 0.32059505248667797\n"
     ]
    }
   ],
   "source": [
    "#overall results for transfer learning from hateval\n",
    "\n",
    "f1_3_transfer = (f1_c_transfer + f1_d_transfer + f1_e_transfer)/3\n",
    "print(\"Macro average F1 for class 3 IND/GRP/OTH is\", f1_3_transfer)\n",
    "print(\"Macro average F1 overall\", (f1_a_transfer + f1_b_transfer + f1_3_transfer)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "def test_new(model, test_loader):\n",
    "  model.load_state_dict(torch.load(base_path + 'WeightsOffenseval/nli_latest_3.pt', map_location=torch.device('cpu')))\n",
    "  model.eval()\n",
    "  total_test_acc  = 0\n",
    "  total_test_loss = 0\n",
    "  start = time.time()\n",
    "  preds = []\n",
    "  acts = []\n",
    "  wrong_examples = []\n",
    "  with torch.no_grad():\n",
    "    #print(\"Prediction\", \"Label\")\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(test_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                           token_type_ids=seg_ids, \n",
    "                           attention_mask=mask_ids, \n",
    "                           labels=labels).values()\n",
    "        \n",
    "      # loss = criterion(prediction, labels)\n",
    "      acc = multi_acc(prediction, labels)\n",
    "      p = prediction.tolist()\n",
    "      tmp = [0 if x[0] > x[1] else 1 for x in p]\n",
    "      for i in range(len(tmp)):\n",
    "        prediction_made = 1 if p[i][1] > p[i][0] else 0\n",
    "        actual_answer = labels[i].item()\n",
    "        if prediction_made != actual_answer:\n",
    "          l = pair_token_ids[i].tolist()\n",
    "          s = mnli_dataset.tokenizer.convert_ids_to_tokens(l)\n",
    "          if '[PAD]' in s:\n",
    "            wrong_examples.append(' '.join(s[1:s.index('[PAD]')]).replace('##', '') + str(actual_answer))\n",
    "          else:\n",
    "            wrong_examples.append(' '.join(s[1:]).replace('##', '') + str(actual_answer))\n",
    "      preds = preds + prediction.tolist()\n",
    "      acts = acts + labels.tolist()\n",
    "      #print(prediction, labels)\n",
    "      total_test_loss += loss.item()\n",
    "      total_test_acc  += acc.item() \n",
    "\n",
    "  test_acc  = total_test_acc/len(test_loader)\n",
    "  test_loss = total_test_loss/len(test_loader)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "  print(f'test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  return preds, acts, wrong_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.4762 test_acc: 0.8200\n",
      "00:00:11.11\n"
     ]
    }
   ],
   "source": [
    "p, a, wrong_examples = test_new(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(base_path + 'Data/OffensEval/wrong_predictions_nli.txt', 'w')\n",
    "for wrong_example in wrong_examples:\n",
    "    f.write(wrong_example + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrong_examples)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sentence Entailment BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0183e10141f049a1820827c9dfbd6c5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d01f56954ef74452b649def7b9adc937",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a4784a513b749d68959b4250a8a1593",
      "value": 28
     }
    },
    "0504a8ce7be543a49611a424fcfc9ca7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1543919f31dd46c6a967a412af4d21bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16b6fa8b34e24eedb7c6c80e9e57b5d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24f1399337dc4cf998e189d697b8e282": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e8aaf8e2a644b8384d07e86578e7624": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30c1af9f395f4f148a4038c1f13b2088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7e7c6e812fdc4b36a25096e9f176f75a",
       "IPY_MODEL_bf7f2daca2264bd289670898d7ab10e4",
       "IPY_MODEL_3af999385a094ccc85eadf702ab69723"
      ],
      "layout": "IPY_MODEL_1543919f31dd46c6a967a412af4d21bd"
     }
    },
    "322cc0d27aea4458a9efe1c099943482": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0d781c1aae342ae949264fb561b7f5f",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_677cf9fc8f3d47c68e73bd4a3622132b",
      "value": 466062
     }
    },
    "373af73466be45f1bb216e6abbdb15be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3af999385a094ccc85eadf702ab69723": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e50074e3a054225842a6fe8ef936183",
      "placeholder": "",
      "style": "IPY_MODEL_c2496080cc384158856247dd5581e751",
      "value": " 570/570 [00:00&lt;00:00, 13.4kB/s]"
     }
    },
    "3e50074e3a054225842a6fe8ef936183": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "405ea21b2692487298e89e719c6573b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd90fde29e26447c9eaeef9aaf15d01f",
      "placeholder": "",
      "style": "IPY_MODEL_16b6fa8b34e24eedb7c6c80e9e57b5d2",
      "value": "Downloading: 100%"
     }
    },
    "41fe1073e1ea44669cdbef98949f9528": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43f942f812884ace90aa9b1dd41a3d9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45dcdc23c9b4481a9e40878e4dbfd585": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2a5689111c3420c9ed4114bb55cf0fc",
      "placeholder": "",
      "style": "IPY_MODEL_d09c0639c5ef45a7823074eb648de6d7",
      "value": "Downloading: 100%"
     }
    },
    "4720c540eecc4dbe8fee8c9596f56933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "546361d1061243f5b7fc5692b1c9d4c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d80c6db4dfc4bf0aaea82350dffdc21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "602d9b5979084873996eab9784b98edc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6497737147ce458b881bbb1b17492364": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "677cf9fc8f3d47c68e73bd4a3622132b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6b127ca5fb5a4d23b6c3ffe654cdfcaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c0f5454779b4baeafa828e961459116": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a39de3d6df814e98be1a65e049bff39e",
       "IPY_MODEL_ef706620a1e34c3a84de18a03a85f8cd",
       "IPY_MODEL_bfee36d5b72d469cb308f4007e1474a0"
      ],
      "layout": "IPY_MODEL_f17b3761a665477e8fdecfd23d267f87"
     }
    },
    "6f61782328964e4dbdea05bee3797ee9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb792d8fbadc4bb6977a1986a9783e15",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b127ca5fb5a4d23b6c3ffe654cdfcaf",
      "value": 440473133
     }
    },
    "7e7c6e812fdc4b36a25096e9f176f75a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e8aaf8e2a644b8384d07e86578e7624",
      "placeholder": "",
      "style": "IPY_MODEL_d84069b7b1384beaa5100505f9233b2b",
      "value": "Downloading: 100%"
     }
    },
    "814534237a9144deb7d52e4ceffabc43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6497737147ce458b881bbb1b17492364",
      "placeholder": "",
      "style": "IPY_MODEL_373af73466be45f1bb216e6abbdb15be",
      "value": " 420M/420M [00:10&lt;00:00, 36.1MB/s]"
     }
    },
    "8665ae01129141dfb7fdf5037a994c86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93f0f8c7257944e6ab97295f09821f1d",
      "placeholder": "",
      "style": "IPY_MODEL_a61965e1ea50438c868778deb83db312",
      "value": " 28.0/28.0 [00:00&lt;00:00, 518B/s]"
     }
    },
    "89a7fc4f932041a7b76b2502096ede49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8a4784a513b749d68959b4250a8a1593": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "93ded7574b56441eaa9b6aaaa30840f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93f0f8c7257944e6ab97295f09821f1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95d0e5c35a01408fa9bde956d0785d21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_405ea21b2692487298e89e719c6573b0",
       "IPY_MODEL_0183e10141f049a1820827c9dfbd6c5a",
       "IPY_MODEL_8665ae01129141dfb7fdf5037a994c86"
      ],
      "layout": "IPY_MODEL_93ded7574b56441eaa9b6aaaa30840f3"
     }
    },
    "9d383d03f9304bce914326ea0e5d472b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a39de3d6df814e98be1a65e049bff39e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24f1399337dc4cf998e189d697b8e282",
      "placeholder": "",
      "style": "IPY_MODEL_f3dea62699df437c945160dfc42afbd5",
      "value": "Downloading: 100%"
     }
    },
    "a61965e1ea50438c868778deb83db312": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf065a9136dc4262a74c04f746b7c143": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d383d03f9304bce914326ea0e5d472b",
      "placeholder": "",
      "style": "IPY_MODEL_43f942f812884ace90aa9b1dd41a3d9a",
      "value": "Downloading: 100%"
     }
    },
    "bf7f2daca2264bd289670898d7ab10e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d80c6db4dfc4bf0aaea82350dffdc21",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89a7fc4f932041a7b76b2502096ede49",
      "value": 570
     }
    },
    "bfee36d5b72d469cb308f4007e1474a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcde074381814577a68122dd6e5adf30",
      "placeholder": "",
      "style": "IPY_MODEL_4720c540eecc4dbe8fee8c9596f56933",
      "value": " 226k/226k [00:00&lt;00:00, 215kB/s]"
     }
    },
    "c2496080cc384158856247dd5581e751": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c38a9f17f85544b68ffdc8e501a95f20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45dcdc23c9b4481a9e40878e4dbfd585",
       "IPY_MODEL_322cc0d27aea4458a9efe1c099943482",
       "IPY_MODEL_e4669478d1474c4485c45907447d75a5"
      ],
      "layout": "IPY_MODEL_41fe1073e1ea44669cdbef98949f9528"
     }
    },
    "d01f56954ef74452b649def7b9adc937": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d09c0639c5ef45a7823074eb648de6d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d84069b7b1384beaa5100505f9233b2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dcde074381814577a68122dd6e5adf30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd90fde29e26447c9eaeef9aaf15d01f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0c07e3c6bd042c2a3dd2aed325f6759": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0d781c1aae342ae949264fb561b7f5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4669478d1474c4485c45907447d75a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_546361d1061243f5b7fc5692b1c9d4c5",
      "placeholder": "",
      "style": "IPY_MODEL_602d9b5979084873996eab9784b98edc",
      "value": " 455k/455k [00:00&lt;00:00, 691kB/s]"
     }
    },
    "e8a66bb5d7614602ac93db9cac811135": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf065a9136dc4262a74c04f746b7c143",
       "IPY_MODEL_6f61782328964e4dbdea05bee3797ee9",
       "IPY_MODEL_814534237a9144deb7d52e4ceffabc43"
      ],
      "layout": "IPY_MODEL_0504a8ce7be543a49611a424fcfc9ca7"
     }
    },
    "ef706620a1e34c3a84de18a03a85f8cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0c07e3c6bd042c2a3dd2aed325f6759",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff8facd357854c18976dea8f1621cae6",
      "value": 231508
     }
    },
    "f17b3761a665477e8fdecfd23d267f87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2a5689111c3420c9ed4114bb55cf0fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3dea62699df437c945160dfc42afbd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb792d8fbadc4bb6977a1986a9783e15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff8facd357854c18976dea8f1621cae6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
