{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25QT54O2UjEh"
   },
   "source": [
    "Reference: https://github.com/dh1105/Sentence-Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9YGhQEYnj7DD",
    "outputId": "819c882f-b0a1-4459-c424-d46e5be61b4f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uqcn3_lQ5Hhr",
    "outputId": "480b8d47-49e8-407d-cbb0-de91efbd2a15"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install sentencepiece\n",
    "## !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JQ4M8Znd4_ep"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "# import torch_xla\n",
    "# import torch_xla.core.xla_model as xm\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WkpfPDS1Z8a8",
    "outputId": "f7f15058-4a5a-44b3-a978-36a6f499f710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-eyFJM1SstoH"
   },
   "outputs": [],
   "source": [
    "task_a_hyp = \"This is offensive speech.\"\n",
    "task_b_hyp = \"This is targeted offense.\"\n",
    "task_c_hyp_1= \"This is targeted towards an individual.\"\n",
    "task_c_hyp_2 = \"This is targeted towards a group.\"\n",
    "task_c_hyp_3 = \"This isn't targeted towards a group or an individual.\"\n",
    "f = open('Data/OffensEval/olid_train_v2.csv')\n",
    "f_a = open('Data/OffensEval/bert_nli.csv', 'w')\n",
    "f_a.write('tweet_id' + '\\t' + 'gold_label' + '\\t' + 'sentence1' + '\\t' + 'sentence2' + '\\n')\n",
    "lines = f.readlines()\n",
    "for line in lines[1:]:\n",
    "  row = line.split('\\t')\n",
    "  tweet_id = row[0].strip()\n",
    "  tweet_text = ' '.join(row[1:-3]).strip()\n",
    "  is_offensive = row[-3].strip()\n",
    "  is_targeted = row[-2].strip()\n",
    "  target = row[-1].strip()\n",
    "  if is_offensive == 'OFF':\n",
    "    f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_a_hyp + '\\n')\n",
    "    if is_targeted == 'TIN':\n",
    "      f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_b_hyp + '\\n')\n",
    "      if target == 'IND':\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_c_hyp_1 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_2 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_3 + '\\n')\n",
    "      elif target == 'GRP':\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_1 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_c_hyp_2 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_3 + '\\n')\n",
    "      elif target == 'OTH':\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_1 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_c_hyp_2 + '\\n')\n",
    "        f_a.write(tweet_id + '\\t' + 'entailment' + '\\t' + tweet_text + '\\t' + task_c_hyp_3 + '\\n')\n",
    "    elif is_targeted == 'UNT':\n",
    "      f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_b_hyp + '\\n')\n",
    "  else:\n",
    "    f_a.write(tweet_id + '\\t' + 'contradiction' + '\\t' + tweet_text + '\\t' + task_a_hyp + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DCcdjRLDG3Ex"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/OffensEval/bert_nli.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fbQWldbaIOGR"
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FH6Mk5reBrpJ"
   },
   "outputs": [],
   "source": [
    "l = len(df)\n",
    "train_df = df[:int(0.8*l)]\n",
    "val_df = df[int(0.8*l):int(0.9*l)]\n",
    "test_df = df[int(0.9*l):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3NgPYXBg4_e7"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.dropna()\n",
    "val_df = val_df.dropna()\n",
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UMTQb1iMF54W"
   },
   "outputs": [],
   "source": [
    "train_df['sentence1'] = train_df['sentence1'].astype(str)\n",
    "train_df['sentence2'] = train_df['sentence2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GMzPNmtpF8yg"
   },
   "outputs": [],
   "source": [
    "val_df['sentence1'] = val_df['sentence1'].astype(str)\n",
    "val_df['sentence2'] = val_df['sentence2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6UBcmYsPzWA7"
   },
   "outputs": [],
   "source": [
    "test_df['sentence1'] = test_df['sentence1'].astype(str)\n",
    "test_df['sentence2'] = test_df['sentence2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "diS3wCm14_e9"
   },
   "outputs": [],
   "source": [
    "train_df = train_df[(train_df['sentence1'].str.split().str.len() > 0) & (train_df['sentence2'].str.split().str.len() > 0)]\n",
    "val_df = val_df[(val_df['sentence1'].str.split().str.len() > 0) & (val_df['sentence2'].str.split().str.len() > 0)]\n",
    "test_df = test_df[(test_df['sentence1'].str.split().str.len() > 0) & (test_df['sentence2'].str.split().str.len() > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "WinUrXE04_e9",
    "outputId": "6e4a47fe-cad1-4b40-c83f-acef182072c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18190</th>\n",
       "      <td>31639</td>\n",
       "      <td>entailment</td>\n",
       "      <td>According to a student that spoke under condit...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27505</th>\n",
       "      <td>74555</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER It's really slowing me down. I wanna ask...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5453</th>\n",
       "      <td>20777</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>@USER @USER @USER @USER @USER Trump publicly l...</td>\n",
       "      <td>This isn't targeted towards a group or an indi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9458</th>\n",
       "      <td>75929</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER Remind me of Antifa ratbags.</td>\n",
       "      <td>This is targeted offense.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19799</th>\n",
       "      <td>42320</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER @USER @USER @USER Bridget that's another...</td>\n",
       "      <td>This is targeted offense.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12421</th>\n",
       "      <td>11581</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER @USER @USER @USER @USER This is the viol...</td>\n",
       "      <td>This is targeted towards a group.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25556</th>\n",
       "      <td>81405</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER He also said he had a gatlin gun and nig...</td>\n",
       "      <td>This is targeted offense.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12669</th>\n",
       "      <td>80291</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER Fairness?? What about being fair to the ...</td>\n",
       "      <td>This is targeted offense.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22893</th>\n",
       "      <td>42537</td>\n",
       "      <td>entailment</td>\n",
       "      <td>Mueller proves the judicial system is weaponiz...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17849</th>\n",
       "      <td>56888</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER As you typed “you think everyone is like...</td>\n",
       "      <td>This is targeted offense.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22520 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id     gold_label  \\\n",
       "18190     31639     entailment   \n",
       "27505     74555     entailment   \n",
       "5453      20777  contradiction   \n",
       "9458      75929     entailment   \n",
       "19799     42320     entailment   \n",
       "...         ...            ...   \n",
       "12421     11581     entailment   \n",
       "25556     81405     entailment   \n",
       "12669     80291     entailment   \n",
       "22893     42537     entailment   \n",
       "17849     56888     entailment   \n",
       "\n",
       "                                               sentence1  \\\n",
       "18190  According to a student that spoke under condit...   \n",
       "27505  @USER It's really slowing me down. I wanna ask...   \n",
       "5453   @USER @USER @USER @USER @USER Trump publicly l...   \n",
       "9458                  @USER Remind me of Antifa ratbags.   \n",
       "19799  @USER @USER @USER @USER Bridget that's another...   \n",
       "...                                                  ...   \n",
       "12421  @USER @USER @USER @USER @USER This is the viol...   \n",
       "25556  @USER He also said he had a gatlin gun and nig...   \n",
       "12669  @USER Fairness?? What about being fair to the ...   \n",
       "22893  Mueller proves the judicial system is weaponiz...   \n",
       "17849  @USER As you typed “you think everyone is like...   \n",
       "\n",
       "                                               sentence2  \n",
       "18190                          This is offensive speech.  \n",
       "27505                          This is offensive speech.  \n",
       "5453   This isn't targeted towards a group or an indi...  \n",
       "9458                           This is targeted offense.  \n",
       "19799                          This is targeted offense.  \n",
       "...                                                  ...  \n",
       "12421                  This is targeted towards a group.  \n",
       "25556                          This is targeted offense.  \n",
       "12669                          This is targeted offense.  \n",
       "22893                          This is offensive speech.  \n",
       "17849                          This is targeted offense.  \n",
       "\n",
       "[22520 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "6e4dxTks4_e-",
    "outputId": "94ec80ad-9e97-49bf-8b63-4fef22a25fa1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>28601</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>@USER @USER @USER Why can't liberals read?????...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>54841</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER Being the good Christian that he is, he ...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27185</th>\n",
       "      <td>92451</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>.@USER @USER and @USER MP @USER praises the 'i...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>61093</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27082</th>\n",
       "      <td>48637</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER What happens next is whoever inthe GOP v...</td>\n",
       "      <td>This is targeted offense.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>69593</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>This is targeted towards a group.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>10755</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>@USER You are right Joe. I can do an interview...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10139</th>\n",
       "      <td>88558</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER @USER I’m sure this pope is on a first n...</td>\n",
       "      <td>This is targeted towards an individual.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9416</th>\n",
       "      <td>73895</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>IT'S TRUE!  #MAGA #NoCollusion URL</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>66741</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>@USER @USER Also TINA - one for the old school...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2815 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id     gold_label  \\\n",
       "289       28601  contradiction   \n",
       "5587      54841     entailment   \n",
       "27185     92451  contradiction   \n",
       "760       61093  contradiction   \n",
       "27082     48637     entailment   \n",
       "...         ...            ...   \n",
       "2949      69593  contradiction   \n",
       "2312      10755  contradiction   \n",
       "10139     88558     entailment   \n",
       "9416      73895  contradiction   \n",
       "4901      66741  contradiction   \n",
       "\n",
       "                                               sentence1  \\\n",
       "289    @USER @USER @USER Why can't liberals read?????...   \n",
       "5587   @USER Being the good Christian that he is, he ...   \n",
       "27185  .@USER @USER and @USER MP @USER praises the 'i...   \n",
       "760    @USER @USER @USER @USER @USER @USER @USER @USE...   \n",
       "27082  @USER What happens next is whoever inthe GOP v...   \n",
       "...                                                  ...   \n",
       "2949   @USER @USER @USER @USER @USER @USER @USER @USE...   \n",
       "2312   @USER You are right Joe. I can do an interview...   \n",
       "10139  @USER @USER I’m sure this pope is on a first n...   \n",
       "9416                  IT'S TRUE!  #MAGA #NoCollusion URL   \n",
       "4901   @USER @USER Also TINA - one for the old school...   \n",
       "\n",
       "                                     sentence2  \n",
       "289                  This is offensive speech.  \n",
       "5587                 This is offensive speech.  \n",
       "27185                This is offensive speech.  \n",
       "760                  This is offensive speech.  \n",
       "27082                This is targeted offense.  \n",
       "...                                        ...  \n",
       "2949         This is targeted towards a group.  \n",
       "2312                 This is offensive speech.  \n",
       "10139  This is targeted towards an individual.  \n",
       "9416                 This is offensive speech.  \n",
       "4901                 This is offensive speech.  \n",
       "\n",
       "[2815 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-nQRV3wZzlMe",
    "outputId": "601de039-4efc-4156-b7c6-364876406bba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>65785</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>@USER Always thought H Ford was a level headed...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5445</th>\n",
       "      <td>26623</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER @USER @USER So many issues facing Austra...</td>\n",
       "      <td>This is targeted offense.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26548</th>\n",
       "      <td>52777</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>@USER @USER John.  You are winning them over o...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13950</th>\n",
       "      <td>37068</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>@USER He is that stupid!</td>\n",
       "      <td>This isn't targeted towards a group or an indi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20376</th>\n",
       "      <td>19289</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER She is a complete idiot</td>\n",
       "      <td>This is targeted towards an individual.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9305</th>\n",
       "      <td>48788</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER Fucking sucks when the refs are against ...</td>\n",
       "      <td>This is targeted towards an individual.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15725</th>\n",
       "      <td>58638</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>@USER @USER @USER @USER @USER The idea that ca...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>10576</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>@USER this is rei from evangelion concept/desi...</td>\n",
       "      <td>This is offensive speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16942</th>\n",
       "      <td>19659</td>\n",
       "      <td>entailment</td>\n",
       "      <td>@USER @USER Dolt. You’ve become another nail f...</td>\n",
       "      <td>This is targeted offense.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17771</th>\n",
       "      <td>37239</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>@USER u never talk to me shut up[</td>\n",
       "      <td>This is targeted towards a group.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2816 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id     gold_label  \\\n",
       "475       65785  contradiction   \n",
       "5445      26623     entailment   \n",
       "26548     52777  contradiction   \n",
       "13950     37068  contradiction   \n",
       "20376     19289     entailment   \n",
       "...         ...            ...   \n",
       "9305      48788     entailment   \n",
       "15725     58638  contradiction   \n",
       "5257      10576  contradiction   \n",
       "16942     19659     entailment   \n",
       "17771     37239  contradiction   \n",
       "\n",
       "                                               sentence1  \\\n",
       "475    @USER Always thought H Ford was a level headed...   \n",
       "5445   @USER @USER @USER So many issues facing Austra...   \n",
       "26548  @USER @USER John.  You are winning them over o...   \n",
       "13950                           @USER He is that stupid!   \n",
       "20376                      @USER She is a complete idiot   \n",
       "...                                                  ...   \n",
       "9305   @USER Fucking sucks when the refs are against ...   \n",
       "15725  @USER @USER @USER @USER @USER The idea that ca...   \n",
       "5257   @USER this is rei from evangelion concept/desi...   \n",
       "16942  @USER @USER Dolt. You’ve become another nail f...   \n",
       "17771                  @USER u never talk to me shut up[   \n",
       "\n",
       "                                               sentence2  \n",
       "475                            This is offensive speech.  \n",
       "5445                           This is targeted offense.  \n",
       "26548                          This is offensive speech.  \n",
       "13950  This isn't targeted towards a group or an indi...  \n",
       "20376            This is targeted towards an individual.  \n",
       "...                                                  ...  \n",
       "9305             This is targeted towards an individual.  \n",
       "15725                          This is offensive speech.  \n",
       "5257                           This is offensive speech.  \n",
       "16942                          This is targeted offense.  \n",
       "17771                  This is targeted towards a group.  \n",
       "\n",
       "[2816 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "P11Q5BRkX70D"
   },
   "outputs": [],
   "source": [
    "test_df_a = test_df[test_df.sentence2 == \"This is offensive speech.\"].sort_values(by=['tweet_id'])\n",
    "test_df_b = test_df[test_df.sentence2 == \"This is targeted offense.\"].sort_values(by=['tweet_id'])\n",
    "test_df_c = test_df[test_df.sentence2 == \"This is targeted towards an individual.\"].sort_values(by=['tweet_id'])\n",
    "test_df_d = test_df[test_df.sentence2 == \"This is targeted towards a group.\"].sort_values(by=['tweet_id'])\n",
    "test_df_e = test_df[test_df.sentence2 == \"This isn't targeted towards a group or an individual.\"].sort_values(by=['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSjkMi9VZ4N2",
    "outputId": "5f824c54-3425-48d2-faa7-a7f85693565c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1262\n",
      "431\n",
      "398\n",
      "363\n",
      "362\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df_a))\n",
    "print(len(test_df_b))\n",
    "print(len(test_df_c))\n",
    "print(len(test_df_d))\n",
    "print(len(test_df_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Gk96lNh94_e_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pickle\n",
    "import os\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "class MNLIDataBert(Dataset):\n",
    "\n",
    "  def __init__(self, train_df, val_df, test_df, test_df_a, test_df_b, test_df_c, test_df_d, test_df_e):\n",
    "    self.label_dict = {'entailment': 1, 'contradiction': 0}\n",
    "\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "    self.test_df_a = test_df_a\n",
    "    self.test_df_b = test_df_b\n",
    "    self.test_df_c = test_df_c\n",
    "    self.test_df_d = test_df_d\n",
    "    self.test_df_e = test_df_e\n",
    "    self.base_path = 'mnli-data-offenseval'\n",
    "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    self.train_data = None\n",
    "    self.val_data = None\n",
    "    self.test_data = None\n",
    "    self.test_data_a = None\n",
    "    self.test_data_b = None\n",
    "    self.test_data_c = None\n",
    "    self.test_data_d = None\n",
    "    self.test_data_e = None\n",
    "    self.init_data()\n",
    "\n",
    "  def init_data(self):\n",
    "    #Saving takes too much RAM\n",
    "    \n",
    "    if os.path.exists(os.path.join(self.base_path, 'train_data.pkl')):\n",
    "      print(\"Found training data\")\n",
    "      with open(os.path.join(self.base_path, 'train_data.pkl'), 'rb') as f:\n",
    "        self.train_data = pickle.load(f)\n",
    "    else:\n",
    "      self.train_data = self.load_data(self.train_df)\n",
    "      with open(os.path.join(self.base_path, 'train_data.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.train_data, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'val_data.pkl')):\n",
    "      print(\"Found val data\")\n",
    "      with open(os.path.join(self.base_path, 'val_data.pkl'), 'rb') as f:\n",
    "        self.val_data = pickle.load(f)\n",
    "    else:\n",
    "      self.val_data = self.load_data(self.val_df)\n",
    "      with open(os.path.join(self.base_path, 'val_data.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.val_data, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'test_data.pkl')):\n",
    "      print(\"Found test data\")\n",
    "      with open(os.path.join(self.base_path, 'test_data.pkl'), 'rb') as f:\n",
    "        self.test_data = pickle.load(f)\n",
    "    else:\n",
    "      self.test_data = self.load_data(self.test_df)\n",
    "      with open(os.path.join(self.base_path, 'test_data.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.test_data, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'test_data_a.pkl')):\n",
    "      print(\"Found test data a\")\n",
    "      with open(os.path.join(self.base_path, 'test_data_a.pkl'), 'rb') as f:\n",
    "        self.test_data_a = pickle.load(f)\n",
    "    else:\n",
    "      self.test_data_a = self.load_data(self.test_df_a)\n",
    "      with open(os.path.join(self.base_path, 'test_data_a.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.test_data_a, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'test_data_b.pkl')):\n",
    "      print(\"Found test data b\")\n",
    "      with open(os.path.join(self.base_path, 'test_data_b.pkl'), 'rb') as f:\n",
    "        self.test_data_b = pickle.load(f)\n",
    "    else:\n",
    "      self.test_data_b = self.load_data(self.test_df_b)\n",
    "      with open(os.path.join(self.base_path, 'test_data_b.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.test_data_b, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'test_data_c.pkl')):\n",
    "      print(\"Found test data c\")\n",
    "      with open(os.path.join(self.base_path, 'test_data_c.pkl'), 'rb') as f:\n",
    "        self.test_data_c = pickle.load(f)\n",
    "    else:\n",
    "      self.test_data_c = self.load_data(self.test_df_c)\n",
    "      with open(os.path.join(self.base_path, 'test_data_c.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.test_data_c, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'test_data_d.pkl')):\n",
    "      print(\"Found test data d\")\n",
    "      with open(os.path.join(self.base_path, 'test_data_d.pkl'), 'rb') as f:\n",
    "        self.test_data_d = pickle.load(f)\n",
    "    else:\n",
    "      self.test_data_d = self.load_data(self.test_df_d)\n",
    "      with open(os.path.join(self.base_path, 'test_data_d.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.test_data_d, f)\n",
    "    if os.path.exists(os.path.join(self.base_path, 'test_data_e.pkl')):\n",
    "      print(\"Found test data e\")\n",
    "      with open(os.path.join(self.base_path, 'test_data_e.pkl'), 'rb') as f:\n",
    "        self.test_data_e = pickle.load(f)\n",
    "    else:\n",
    "      self.test_data_e = self.load_data(self.test_df_e)\n",
    "      with open(os.path.join(self.base_path, 'test_data_e.pkl'), 'wb') as f:\n",
    "        pickle.dump(self.test_data_e, f)\n",
    "    # self.train_data = self.load_data(self.train_df)\n",
    "    # self.val_data = self.load_data(self.val_df)\n",
    "    # self.test_data = self.load_data(self.test_df)\n",
    "  def load_data(self, df):\n",
    "    MAX_LEN = 512\n",
    "    token_ids = []\n",
    "    mask_ids = []\n",
    "    seg_ids = []\n",
    "    y = []\n",
    "\n",
    "    premise_list = df['sentence1'].to_list()\n",
    "    hypothesis_list = df['sentence2'].to_list()\n",
    "    label_list = df['gold_label'].to_list()\n",
    "\n",
    "    for (premise, hypothesis, label) in zip(premise_list, hypothesis_list, label_list):\n",
    "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
    "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
    "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n",
    "      premise_len = len(premise_id)\n",
    "      hypothesis_len = len(hypothesis_id)\n",
    "\n",
    "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
    "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
    "\n",
    "      token_ids.append(torch.tensor(pair_token_ids))\n",
    "      seg_ids.append(segment_ids)\n",
    "      mask_ids.append(attention_mask_ids)\n",
    "      y.append(self.label_dict[label])\n",
    "    \n",
    "    token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "    y = torch.tensor(y)\n",
    "    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n",
    "    print(len(dataset))\n",
    "    return dataset\n",
    "\n",
    "  def get_data_loaders(self, batch_size=32, shuffle=True):\n",
    "    train_loader = DataLoader(\n",
    "      self.train_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "      self.val_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "      self.test_data,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader_a = DataLoader(\n",
    "      self.test_data_a,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader_b = DataLoader(\n",
    "      self.test_data_b,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader_c = DataLoader(\n",
    "      self.test_data_c,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader_d = DataLoader(\n",
    "      self.test_data_d,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_loader_e = DataLoader(\n",
    "      self.test_data_e,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader, test_loader_a, test_loader_b, test_loader_c, test_loader_d, test_loader_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284,
     "referenced_widgets": [
      "6c0f5454779b4baeafa828e961459116",
      "f17b3761a665477e8fdecfd23d267f87",
      "a39de3d6df814e98be1a65e049bff39e",
      "ef706620a1e34c3a84de18a03a85f8cd",
      "bfee36d5b72d469cb308f4007e1474a0",
      "f3dea62699df437c945160dfc42afbd5",
      "24f1399337dc4cf998e189d697b8e282",
      "ff8facd357854c18976dea8f1621cae6",
      "e0c07e3c6bd042c2a3dd2aed325f6759",
      "4720c540eecc4dbe8fee8c9596f56933",
      "dcde074381814577a68122dd6e5adf30",
      "95d0e5c35a01408fa9bde956d0785d21",
      "93ded7574b56441eaa9b6aaaa30840f3",
      "405ea21b2692487298e89e719c6573b0",
      "0183e10141f049a1820827c9dfbd6c5a",
      "8665ae01129141dfb7fdf5037a994c86",
      "16b6fa8b34e24eedb7c6c80e9e57b5d2",
      "dd90fde29e26447c9eaeef9aaf15d01f",
      "8a4784a513b749d68959b4250a8a1593",
      "d01f56954ef74452b649def7b9adc937",
      "a61965e1ea50438c868778deb83db312",
      "93f0f8c7257944e6ab97295f09821f1d",
      "c38a9f17f85544b68ffdc8e501a95f20",
      "41fe1073e1ea44669cdbef98949f9528",
      "45dcdc23c9b4481a9e40878e4dbfd585",
      "322cc0d27aea4458a9efe1c099943482",
      "e4669478d1474c4485c45907447d75a5",
      "d09c0639c5ef45a7823074eb648de6d7",
      "f2a5689111c3420c9ed4114bb55cf0fc",
      "677cf9fc8f3d47c68e73bd4a3622132b",
      "e0d781c1aae342ae949264fb561b7f5f",
      "602d9b5979084873996eab9784b98edc",
      "546361d1061243f5b7fc5692b1c9d4c5",
      "30c1af9f395f4f148a4038c1f13b2088",
      "1543919f31dd46c6a967a412af4d21bd",
      "7e7c6e812fdc4b36a25096e9f176f75a",
      "bf7f2daca2264bd289670898d7ab10e4",
      "3af999385a094ccc85eadf702ab69723",
      "d84069b7b1384beaa5100505f9233b2b",
      "2e8aaf8e2a644b8384d07e86578e7624",
      "89a7fc4f932041a7b76b2502096ede49",
      "5d80c6db4dfc4bf0aaea82350dffdc21",
      "c2496080cc384158856247dd5581e751",
      "3e50074e3a054225842a6fe8ef936183"
     ]
    },
    "id": "md52P1z14_e_",
    "outputId": "e875db6f-6bb9-44a1-f2de-0e8cbea3e883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22520\n",
      "2815\n",
      "2816\n",
      "1262\n",
      "431\n",
      "398\n",
      "363\n",
      "362\n"
     ]
    }
   ],
   "source": [
    "mnli_dataset = MNLIDataBert(train_df, val_df, test_df, test_df_a, test_df_b, test_df_c, test_df_d, test_df_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-LSyABLG4_fA"
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, test_loader_a, test_loader_b, test_loader_c, test_loader_d, test_loader_e = mnli_dataset.get_data_loaders(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e8a66bb5d7614602ac93db9cac811135",
      "0504a8ce7be543a49611a424fcfc9ca7",
      "bf065a9136dc4262a74c04f746b7c143",
      "6f61782328964e4dbdea05bee3797ee9",
      "814534237a9144deb7d52e4ceffabc43",
      "43f942f812884ace90aa9b1dd41a3d9a",
      "9d383d03f9304bce914326ea0e5d472b",
      "6b127ca5fb5a4d23b6c3ffe654cdfcaf",
      "fb792d8fbadc4bb6977a1986a9783e15",
      "373af73466be45f1bb216e6abbdb15be",
      "6497737147ce458b881bbb1b17492364"
     ]
    },
    "id": "qOdc4Cs2DEjt",
    "outputId": "7cdbd55e-a6e6-4cad-e765-de1a18e3f0c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jxzpENXlEh-u"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "is1TqwTREid9"
   },
   "outputs": [],
   "source": [
    "# This variable contains all of the hyperparemeter information our training loop needs\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79aI1dun4_fB",
    "outputId": "eb5cbe4e-f9fa-4618-d840-611d259037f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 109,483,778 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qhU855Cw4_fB"
   },
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "OfhYO7Db4_fB"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer):  \n",
    "  total_step = len(train_loader)\n",
    "  #model.load_state_dict(torch.load('/content/drive/MyDrive/COMPSCI 685 Advanced Natural Language Processing/Project/Weights/nli_0.pt'))\n",
    "  #model.load_state_dict(torch.load('./Weights/nli_3.pt'))\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_train_acc  = 0\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_loader):\n",
    "      optimizer.zero_grad()\n",
    "      if batch_idx%100 == 0:\n",
    "          print(batch_idx, len(train_loader))\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "      # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "\n",
    "      # loss = criterion(prediction, labels)\n",
    "      acc = multi_acc(prediction, labels)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      total_train_loss += loss.item()\n",
    "      total_train_acc  += acc.item()\n",
    "\n",
    "    train_acc  = total_train_acc/len(train_loader)\n",
    "    train_loss = total_train_loss/len(train_loader)\n",
    "    model.eval()\n",
    "    total_val_acc  = 0\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "      for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(val_loader):\n",
    "        optimizer.zero_grad()\n",
    "        pair_token_ids = pair_token_ids.to(device)\n",
    "        mask_ids = mask_ids.to(device)\n",
    "        seg_ids = seg_ids.to(device)\n",
    "        labels = y.to(device)\n",
    "\n",
    "        # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "        loss, prediction = model(pair_token_ids, \n",
    "                             token_type_ids=seg_ids, \n",
    "                             attention_mask=mask_ids, \n",
    "                             labels=labels).values()\n",
    "        \n",
    "        # loss = criterion(prediction, labels)\n",
    "        acc = multi_acc(prediction, labels)\n",
    "\n",
    "        total_val_loss += loss.item()\n",
    "        total_val_acc  += acc.item()\n",
    "\n",
    "    val_acc  = total_val_acc/len(val_loader)\n",
    "    val_loss = total_val_loss/len(val_loader)\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    #torch.save(model.state_dict(),os.path.join('/content/drive/MyDrive/COMPSCI 685 Advanced Natural Language Processing/Project/Weights', 'nli_{}.pt'.format(epoch)))\n",
    "    torch.save(model.state_dict(),os.path.join('./WeightsOffenseval', 'nli_latest_{}.pt'.format(epoch)))\n",
    "    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n",
    "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "TisZ5o86nkMW"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "def test(model, test_loader):\n",
    "  model.load_state_dict(torch.load('WeightsOffenseval/nli_latest_3.pt', map_location=torch.device('cpu')))\n",
    "  #model.load_state_dict(torch.load('WeightsHateval/nli_new_4.pt', map_location=torch.device('cpu')))\n",
    "  model.eval()\n",
    "  total_test_acc  = 0\n",
    "  total_test_loss = 0\n",
    "  start = time.time()\n",
    "  preds = []\n",
    "  acts = []\n",
    "  with torch.no_grad():\n",
    "    #print(\"Prediction\", \"Label\")\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(test_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "\n",
    "      # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                           token_type_ids=seg_ids, \n",
    "                           attention_mask=mask_ids, \n",
    "                           labels=labels).values()\n",
    "        \n",
    "      # loss = criterion(prediction, labels)\n",
    "      acc = multi_acc(prediction, labels)\n",
    "      preds = preds + prediction.tolist()\n",
    "      acts = acts + labels.tolist()\n",
    "      #print(prediction, labels)\n",
    "      total_test_loss += loss.item()\n",
    "      total_test_acc  += acc.item() \n",
    "\n",
    "  test_acc  = total_test_acc/len(test_loader)\n",
    "  test_loss = total_test_loss/len(test_loader)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "  print(f'test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  #return [math.exp(preds[i][1])/(math.exp(preds[i][0] + math.exp(preds[i][1]))) for i in range(len(preds))], acts\n",
    "  #return [0 if preds[i][0] > preds[i][1] else 1 for i in range(len(preds))], acts\n",
    "  return preds, acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPIxT4RB4_fC",
    "outputId": "9af2f2cb-4099-4673-f834-18bcc9bfcac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 352\n",
      "100 352\n",
      "200 352\n",
      "300 352\n",
      "Epoch 1: train_loss: 0.4962 train_acc: 0.7625 | val_loss: 0.3994 val_acc: 0.8338\n",
      "00:10:06.23\n",
      "0 352\n",
      "100 352\n",
      "200 352\n",
      "300 352\n",
      "Epoch 2: train_loss: 0.3808 train_acc: 0.8397 | val_loss: 0.3962 val_acc: 0.8263\n",
      "00:10:06.98\n",
      "0 352\n",
      "100 352\n",
      "200 352\n",
      "300 352\n",
      "Epoch 3: train_loss: 0.2972 train_acc: 0.8819 | val_loss: 0.4250 val_acc: 0.8320\n",
      "00:10:07.11\n",
      "0 352\n",
      "100 352\n",
      "200 352\n",
      "300 352\n",
      "Epoch 4: train_loss: 0.2133 train_acc: 0.9191 | val_loss: 0.4321 val_acc: 0.8444\n",
      "00:10:06.42\n",
      "0 352\n",
      "100 352\n",
      "200 352\n",
      "300 352\n",
      "Epoch 5: train_loss: 0.1549 train_acc: 0.9438 | val_loss: 0.4614 val_acc: 0.8419\n",
      "00:10:06.74\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "3nGBLgp312AD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.4463 test_acc: 0.8420\n",
      "00:00:24.93\n"
     ]
    }
   ],
   "source": [
    "preds, acts = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5w11ZMTvp6yr",
    "outputId": "879fa89b-bfca-4b6e-a749-d77eb8239ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.5944 test_acc: 0.7969\n",
      "00:00:10.40\n"
     ]
    }
   ],
   "source": [
    "preds_a, acts_a = test(model, test_loader_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 288, FP: 132\n",
      "FN: 124, TN: 718\n",
      "Recall: 0.6990291262135923\n",
      "Precsion: 0.6857142857142857\n",
      "F1: 0.6923076923076924\n",
      "Accuracy 0.7971473851030111\n"
     ]
    }
   ],
   "source": [
    "#CLASS A:\n",
    "tp_a = 0\n",
    "fp_a = 0\n",
    "tn_a = 0\n",
    "fn_a = 0\n",
    "preds_a = [math.exp(preds_a[i][1])/(math.exp(preds_a[i][0]) + math.exp(preds_a[i][1])) for i in range(len(preds_a))]\n",
    "for i in range(len(preds_a)):\n",
    "    if acts_a[i] == 1:\n",
    "        if preds_a[i] >= 0.5:\n",
    "            tp_a += 1\n",
    "        else:\n",
    "            fn_a += 1\n",
    "    else:\n",
    "        if preds_a[i] < 0.5:\n",
    "            tn_a += 1\n",
    "        else:\n",
    "            fp_a += 1\n",
    "accuracy_a = (tp_a + tn_a)/(tp_a + fp_a + fn_a + tn_a)\n",
    "recall_a = tp_a/(tp_a + fn_a)\n",
    "precision_a = tp_a/(tp_a + fp_a)\n",
    "f1_a = (2*precision_a*recall_a)/(precision_a + recall_a)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_a, fp_a, fn_a, tn_a))\n",
    "print(\"Recall:\", recall_a)\n",
    "print(\"Precsion:\", precision_a)\n",
    "print(\"F1:\", f1_a)\n",
    "print(\"Accuracy\", accuracy_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total offensive examples: 412\n",
      "Correctly predicted offensive examples: 288\n",
      "Accuracy for predicting offensive examples: 0.6990291262135923\n",
      "Total non offensive examples: 850\n",
      "Correctly predicted non offensive examples: 718\n",
      "Accuracy for predicting non offensive examples: 0.8447058823529412\n"
     ]
    }
   ],
   "source": [
    "ent_acts_a = 0\n",
    "cont_acts_a = 0\n",
    "correct_ents_a = 0\n",
    "correct_conts_a = 0\n",
    "for i in range(len(preds_a)):\n",
    "    if acts_a[i] == 1:\n",
    "        ent_acts_a += 1\n",
    "        if preds_a[i] >= 0.5:\n",
    "            correct_ents_a += 1\n",
    "    else:\n",
    "        cont_acts_a += 1\n",
    "        if preds_a[i] < 0.5:\n",
    "            correct_conts_a += 1\n",
    "            \n",
    "print(\"Total offensive examples:\", ent_acts_a)\n",
    "print(\"Correctly predicted offensive examples:\", correct_ents_a)\n",
    "print(\"Accuracy for predicting offensive examples:\", correct_ents_a/ent_acts_a)\n",
    "print(\"Total non offensive examples:\", cont_acts_a)\n",
    "print(\"Correctly predicted non offensive examples:\", correct_conts_a)\n",
    "print(\"Accuracy for predicting non offensive examples:\", correct_conts_a/cont_acts_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "uqIU3lTPqLkV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.3126 test_acc: 0.8971\n",
      "00:00:02.51\n"
     ]
    }
   ],
   "source": [
    "preds_b, acts_b = test(model, test_loader_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 376, FP: 32\n",
      "FN: 13, TN: 10\n",
      "Recall: 0.9665809768637532\n",
      "Precsion: 0.9215686274509803\n",
      "F1: 0.9435382685069008\n",
      "Accuracy 0.8955916473317865\n"
     ]
    }
   ],
   "source": [
    "#CLASS B:\n",
    "tp_b = 0\n",
    "fp_b = 0\n",
    "tn_b = 0\n",
    "fn_b = 0\n",
    "preds_b = [math.exp(preds_b[i][1])/(math.exp(preds_b[i][0]) + math.exp(preds_b[i][1])) for i in range(len(preds_b))]\n",
    "for i in range(len(preds_b)):\n",
    "    if acts_b[i] == 1:\n",
    "        if preds_b[i] >= 0.5:\n",
    "            tp_b += 1\n",
    "        else:\n",
    "            fn_b += 1\n",
    "    else:\n",
    "        if preds_b[i] < 0.5:\n",
    "            tn_b += 1\n",
    "        else:\n",
    "            fp_b += 1\n",
    "accuracy_b = (tp_b + tn_b)/(tp_b + fp_b + fn_b + tn_b)\n",
    "recall_b = tp_b/(tp_b + fn_b)\n",
    "precision_b = tp_b/(tp_b + fp_b)\n",
    "f1_b = (2*precision_b*recall_b)/(precision_b + recall_b)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_b, fp_b, fn_b, tn_b))\n",
    "print(\"Recall:\", recall_b)\n",
    "print(\"Precsion:\", precision_b)\n",
    "print(\"F1:\", f1_b)\n",
    "print(\"Accuracy\", accuracy_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total targeted offensive examples: 389\n",
      "Correctly predicted targeted offensive examples: 376\n",
      "Accuracy for predicting targeted offensive examples: 0.9665809768637532\n",
      "Total non targeted offensive examples: 42\n",
      "Correctly predicted non targeted offensive examples: 10\n",
      "Accuracy for predicting non targeted offensive examples: 0.23809523809523808\n"
     ]
    }
   ],
   "source": [
    "ent_acts_b = 0\n",
    "cont_acts_b = 0\n",
    "correct_ents_b = 0\n",
    "correct_conts_b = 0\n",
    "for i in range(len(preds_b)):\n",
    "    if acts_b[i] == 1:\n",
    "        ent_acts_b += 1\n",
    "        if preds_b[i] > 0.5:\n",
    "            correct_ents_b += 1\n",
    "    else:\n",
    "        cont_acts_b += 1\n",
    "        if preds_b[i] < 0.5:\n",
    "            correct_conts_b += 1\n",
    "            \n",
    "print(\"Total targeted offensive examples:\", ent_acts_b)\n",
    "print(\"Correctly predicted targeted offensive examples:\", correct_ents_b)\n",
    "print(\"Accuracy for predicting targeted offensive examples:\", correct_ents_b/ent_acts_b)\n",
    "print(\"Total non targeted offensive examples:\", cont_acts_b)\n",
    "print(\"Correctly predicted non targeted offensive examples:\", correct_conts_b)\n",
    "print(\"Accuracy for predicting non targeted offensive examples:\", correct_conts_b/cont_acts_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8TyO6pUpqk1i",
    "outputId": "a1fa4716-4858-4ede-b8f5-89828ca0d40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.3601 test_acc: 0.8747\n",
      "00:00:03.56\n"
     ]
    }
   ],
   "source": [
    "preds_c, acts_c = test(model, test_loader_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 210, FP: 19\n",
      "FN: 30, TN: 139\n",
      "Recall: 0.875\n",
      "Precsion: 0.9170305676855895\n",
      "F1: 0.8955223880597014\n",
      "Accuracy 0.8768844221105527\n"
     ]
    }
   ],
   "source": [
    "#CLASS C:\n",
    "tp_c = 0\n",
    "fp_c = 0\n",
    "tn_c = 0\n",
    "fn_c = 0\n",
    "preds_c = [math.exp(preds_c[i][1])/(math.exp(preds_c[i][0]) + math.exp(preds_c[i][1])) for i in range(len(preds_c))]\n",
    "for i in range(len(preds_c)):\n",
    "    if acts_c[i] == 1:\n",
    "        if preds_c[i] >= 0.5:\n",
    "            tp_c += 1\n",
    "        else:\n",
    "            fn_c += 1\n",
    "    else:\n",
    "        if preds_c[i] < 0.5:\n",
    "            tn_c += 1\n",
    "        else:\n",
    "            fp_c += 1\n",
    "accuracy_c = (tp_c + tn_c)/(tp_c + fp_c + fn_c + tn_c)\n",
    "recall_c = tp_c/(tp_c + fn_c)\n",
    "precision_c = tp_c/(tp_c + fp_c)\n",
    "f1_c = (2*precision_c*recall_c)/(precision_c + recall_c)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_c, fp_c, fn_c, tn_c))\n",
    "print(\"Recall:\", recall_c)\n",
    "print(\"Precsion:\", precision_c)\n",
    "print(\"F1:\", f1_c)\n",
    "print(\"Accuracy\", accuracy_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total individual targeted offensive examples: 224\n",
      "Correctly predicted individual targeted offensive examples: 198\n",
      "Accuracy for predicting individual targeted offensive examples: 0.8839285714285714\n",
      "Total non individual targeted offensive examples: 135\n",
      "Correctly predicted non individual targeted offensive examples: 114\n",
      "Accuracy for predicting non individual targeted offensive examples: 0.8444444444444444\n"
     ]
    }
   ],
   "source": [
    "ent_acts_c = 0\n",
    "cont_acts_c = 0\n",
    "correct_ents_c = 0\n",
    "correct_conts_c = 0\n",
    "for i in range(len(preds_c)):\n",
    "    if acts_c[i] == 1:\n",
    "        ent_acts_c += 1\n",
    "        if preds_c[i] >= 0.5:\n",
    "            correct_ents_c += 1\n",
    "    else:\n",
    "        cont_acts_c += 1\n",
    "        if preds_c[i] < 1:\n",
    "            correct_conts_c += 1\n",
    "            \n",
    "print(\"Total individual targeted offensive examples:\", ent_acts_c)\n",
    "print(\"Correctly predicted individual targeted offensive examples:\", correct_ents_c)\n",
    "print(\"Accuracy for predicting individual targeted offensive examples:\", correct_ents_c/ent_acts_c)\n",
    "print(\"Total non individual targeted offensive examples:\", cont_acts_c)\n",
    "print(\"Correctly predicted non individual targeted offensive examples:\", correct_conts_c)\n",
    "print(\"Accuracy for predicting non individual targeted offensive examples:\", correct_conts_c/cont_acts_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZOu6kmwq9MM",
    "outputId": "8e8af0bb-8565-44fc-e2e6-1ecac75c810b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.4307 test_acc: 0.8297\n",
      "00:00:01.63\n"
     ]
    }
   ],
   "source": [
    "preds_d, acts_d = test(model, test_loader_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 82, FP: 40\n",
      "FN: 21, TN: 220\n",
      "Recall: 0.7961165048543689\n",
      "Precsion: 0.6721311475409836\n",
      "F1: 0.7288888888888888\n",
      "Accuracy 0.8319559228650137\n"
     ]
    }
   ],
   "source": [
    "#CLASS D:\n",
    "tp_d = 0\n",
    "fp_d = 0\n",
    "tn_d = 0\n",
    "fn_d = 0\n",
    "preds_d = [math.exp(preds_d[i][1])/(math.exp(preds_d[i][0]) + math.exp(preds_d[i][1])) for i in range(len(preds_d))]\n",
    "for i in range(len(preds_d)):\n",
    "    if acts_d[i] == 1:\n",
    "        if preds_d[i] >= 0.5:\n",
    "            tp_d += 1\n",
    "        else:\n",
    "            fn_d += 1\n",
    "    else:\n",
    "        if preds_d[i] < 0.5:\n",
    "            tn_d += 1\n",
    "        else:\n",
    "            fp_d += 1\n",
    "accuracy_d = (tp_d + tn_d)/(tp_d + fp_d + fn_d + tn_d)\n",
    "recall_d = tp_d/(tp_d + fn_d)\n",
    "precision_d = tp_d/(tp_d + fp_d)\n",
    "f1_d = (2*precision_d*recall_d)/(precision_d + recall_d)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_d, fp_d, fn_d, tn_d))\n",
    "print(\"Recall:\", recall_d)\n",
    "print(\"Precsion:\", precision_d)\n",
    "print(\"F1:\", f1_d)\n",
    "print(\"Accuracy\", accuracy_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total group targeted offensive examples: 103\n",
      "Correctly predicted group targeted offensive examples: 82\n",
      "Accuracy for predicting group targeted offensive examples: 0.7961165048543689\n",
      "Total non group targeted offensive examples: 260\n",
      "Correctly predicted non group targeted offensive examples: 220\n",
      "Accuracy for predicting non group targeted offensive examples: 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "ent_acts_d = 0\n",
    "cont_acts_d = 0\n",
    "correct_ents_d = 0\n",
    "correct_conts_d = 0\n",
    "for i in range(len(preds_d)):\n",
    "    if acts_d[i] == 1:\n",
    "        ent_acts_d += 1\n",
    "        if preds_d[i] >= 0.5:\n",
    "            correct_ents_d += 1\n",
    "    else:\n",
    "        cont_acts_d += 1\n",
    "        if preds_d[i] < 0.5:\n",
    "            correct_conts_d += 1\n",
    "            \n",
    "print(\"Total group targeted offensive examples:\", ent_acts_d)\n",
    "print(\"Correctly predicted group targeted offensive examples:\", correct_ents_d)\n",
    "print(\"Accuracy for predicting group targeted offensive examples:\", correct_ents_d/ent_acts_d)\n",
    "print(\"Total non group targeted offensive examples:\", cont_acts_d)\n",
    "print(\"Correctly predicted non group targeted offensive examples:\", correct_conts_d)\n",
    "print(\"Accuracy for predicting non group targeted offensive examples:\", correct_conts_d/cont_acts_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUU1YuTIq_z3",
    "outputId": "b76f41c6-8267-4187-b31b-cd49df2c4f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.2136 test_acc: 0.9060\n",
      "00:00:02.36\n"
     ]
    }
   ],
   "source": [
    "preds_e, acts_e = test(model, test_loader_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 2, FP: 4\n",
      "FN: 30, TN: 326\n",
      "Recall: 0.0625\n",
      "Precsion: 0.3333333333333333\n",
      "F1: 0.10526315789473684\n",
      "Accuracy 0.9060773480662984\n"
     ]
    }
   ],
   "source": [
    "#CLASS E:\n",
    "tp_e = 0\n",
    "fp_e = 0\n",
    "tn_e = 0\n",
    "fn_e = 0\n",
    "preds_e = [math.exp(preds_e[i][1])/(math.exp(preds_e[i][0]) + math.exp(preds_e[i][1])) for i in range(len(preds_e))]\n",
    "for i in range(len(preds_e)):\n",
    "    if acts_e[i] == 1:\n",
    "        if preds_e[i] >= 0.5:\n",
    "            tp_e += 1\n",
    "        else:\n",
    "            fn_e += 1\n",
    "    else:\n",
    "        if preds_e[i] < 0.5:\n",
    "            tn_e += 1\n",
    "        else:\n",
    "            fp_e += 1\n",
    "accuracy_e = (tp_e + tn_e)/(tp_e + fp_e + fn_e + tn_e)\n",
    "recall_e = tp_e/(tp_e + fn_e)\n",
    "precision_e = tp_e/(tp_e + fp_e)\n",
    "f1_e = (2*precision_e*recall_e)/(precision_e + recall_e)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_e, fp_e, fn_e, tn_e))\n",
    "print(\"Recall:\", recall_e)\n",
    "print(\"Precsion:\", precision_e)\n",
    "print(\"F1:\", f1_e)\n",
    "print(\"Accuracy\", accuracy_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total other targeted offensive examples: 32\n",
      "Correctly predicted other targeted offensive examples: 2\n",
      "Accuracy for predicting other targeted offensive examples: 0.0625\n",
      "Total non other targeted offensive examples: 330\n",
      "Correctly predicted non other targeted offensive examples: 326\n",
      "Accuracy for predicting non other targeted offensive examples: 0.9878787878787879\n"
     ]
    }
   ],
   "source": [
    "ent_acts_e = 0\n",
    "cont_acts_e = 0\n",
    "correct_ents_e = 0\n",
    "correct_conts_e = 0\n",
    "for i in range(len(preds_e)):\n",
    "    if acts_e[i] == 1:\n",
    "        ent_acts_e += 1\n",
    "        if preds_e[i] >= 0.5:\n",
    "            correct_ents_e += 1\n",
    "    else:\n",
    "        cont_acts_e += 1\n",
    "        if preds_e[i] < 0.5:\n",
    "            correct_conts_e += 1\n",
    "            \n",
    "print(\"Total other targeted offensive examples:\", ent_acts_e)\n",
    "print(\"Correctly predicted other targeted offensive examples:\", correct_ents_e)\n",
    "print(\"Accuracy for predicting other targeted offensive examples:\", correct_ents_e/ent_acts_e)\n",
    "print(\"Total non other targeted offensive examples:\", cont_acts_e)\n",
    "print(\"Correctly predicted non other targeted offensive examples:\", correct_conts_e)\n",
    "print(\"Accuracy for predicting non other targeted offensive examples:\", correct_conts_e/cont_acts_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro average F1 for class 3 IND/GRP/OTH is 0.5765581449477756\n",
      "Macro average F1 overall 0.737468035254123\n"
     ]
    }
   ],
   "source": [
    "f1_3 = (f1_c + f1_d + f1_e)/3\n",
    "print(\"Macro average F1 for class 3 IND/GRP/OTH is\", f1_3)\n",
    "print(\"Macro average F1 overall\", (f1_a + f1_b + f1_3)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transfer(model, test_loader):\n",
    "  #model.load_state_dict(torch.load('WeightsOffenseval/nli_latest_3.pt', map_location=torch.device('cpu')))\n",
    "  model.load_state_dict(torch.load('WeightsHateval/nli_new_4.pt', map_location=torch.device('cpu')))\n",
    "  model.eval()\n",
    "  total_test_acc  = 0\n",
    "  total_test_loss = 0\n",
    "  start = time.time()\n",
    "  preds = []\n",
    "  acts = []\n",
    "  with torch.no_grad():\n",
    "    #print(\"Prediction\", \"Label\")\n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(test_loader):\n",
    "      optimizer.zero_grad()\n",
    "      pair_token_ids = pair_token_ids.to(device)\n",
    "      mask_ids = mask_ids.to(device)\n",
    "      seg_ids = seg_ids.to(device)\n",
    "      labels = y.to(device)\n",
    "\n",
    "      # prediction = model(pair_token_ids, mask_ids, seg_ids)\n",
    "      loss, prediction = model(pair_token_ids, \n",
    "                           token_type_ids=seg_ids, \n",
    "                           attention_mask=mask_ids, \n",
    "                           labels=labels).values()\n",
    "        \n",
    "      # loss = criterion(prediction, labels)\n",
    "      acc = multi_acc(prediction, labels)\n",
    "      preds = preds + prediction.tolist()\n",
    "      acts = acts + labels.tolist()\n",
    "      #print(prediction, labels)\n",
    "      total_test_loss += loss.item()\n",
    "      total_test_acc  += acc.item() \n",
    "\n",
    "  test_acc  = total_test_acc/len(test_loader)\n",
    "  test_loss = total_test_loss/len(test_loader)\n",
    "  end = time.time()\n",
    "  hours, rem = divmod(end-start, 3600)\n",
    "  minutes, seconds = divmod(rem, 60)\n",
    "  print(f'test_loss: {test_loss:.4f} test_acc: {test_acc:.4f}')\n",
    "  print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "  #return [math.exp(preds[i][1])/(math.exp(preds[i][0] + math.exp(preds[i][1]))) for i in range(len(preds))], acts\n",
    "  #return [0 if preds[i][0] > preds[i][1] else 1 for i in range(len(preds))], acts\n",
    "  return preds, acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.6622 test_acc: 0.6454\n",
      "00:00:10.31\n"
     ]
    }
   ],
   "source": [
    "preds_a_transfer, acts_a_transfer = test_transfer(model, test_loader_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 2.5022 test_acc: 0.4186\n",
      "00:00:02.48\n"
     ]
    }
   ],
   "source": [
    "preds_b_transfer, acts_b_transfer = test_transfer(model, test_loader_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.9492 test_acc: 0.5555\n",
      "00:00:03.54\n"
     ]
    }
   ],
   "source": [
    "preds_c_transfer, acts_c_transfer = test_transfer(model, test_loader_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 2.1514 test_acc: 0.4551\n",
      "00:00:01.65\n"
     ]
    }
   ],
   "source": [
    "preds_d_transfer, acts_d_transfer = test_transfer(model, test_loader_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.1987 test_acc: 0.6226\n",
      "00:00:02.34\n"
     ]
    }
   ],
   "source": [
    "preds_e_transfer, acts_e_transfer = test_transfer(model, test_loader_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 32, FP: 29\n",
      "FN: 90, TN: 211\n",
      "Recall: 0.26229508196721313\n",
      "Precsion: 0.5245901639344263\n",
      "F1: 0.3497267759562842\n",
      "Accuracy 0.6712707182320442\n"
     ]
    }
   ],
   "source": [
    "#CLASS A: Transfer learning from hateval\n",
    "\n",
    "tp_a_transfer = 0\n",
    "fp_a_transfer = 0\n",
    "tn_a_transfer = 0\n",
    "fn_a_transfer = 0\n",
    "preds_a_transfer = [math.exp(preds_a_transfer[i][1])/(math.exp(preds_a_transfer[i][0]) + math.exp(preds_a_transfer[i][1])) for i in range(len(preds_e))]\n",
    "for i in range(len(preds_a_transfer)):\n",
    "    if acts_a_transfer[i] == 1:\n",
    "        if preds_a_transfer[i] >= 0.5:\n",
    "            tp_a_transfer += 1\n",
    "        else:\n",
    "            fn_a_transfer += 1\n",
    "    else:\n",
    "        if preds_a_transfer[i] < 0.5:\n",
    "            tn_a_transfer += 1\n",
    "        else:\n",
    "            fp_a_transfer += 1\n",
    "accuracy_a_transfer = (tp_a_transfer + tn_a_transfer)/(tp_a_transfer + fp_a_transfer + fn_a_transfer + tn_a_transfer)\n",
    "recall_a_transfer = tp_a_transfer/(tp_a_transfer + fn_a_transfer)\n",
    "precision_a_transfer = tp_a_transfer/(tp_a_transfer + fp_a_transfer)\n",
    "f1_a_transfer = (2*precision_a_transfer*recall_a_transfer)/(precision_a_transfer + recall_a_transfer)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_a_transfer, fp_a_transfer, fn_a_transfer, tn_a_transfer))\n",
    "print(\"Recall:\", recall_a_transfer)\n",
    "print(\"Precsion:\", precision_a_transfer)\n",
    "print(\"F1:\", f1_a_transfer)\n",
    "print(\"Accuracy\", accuracy_a_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 130, FP: 8\n",
      "FN: 198, TN: 26\n",
      "Recall: 0.39634146341463417\n",
      "Precsion: 0.9420289855072463\n",
      "F1: 0.5579399141630902\n",
      "Accuracy 0.430939226519337\n"
     ]
    }
   ],
   "source": [
    "#CLASS B: Transfer learning from hateval\n",
    "\n",
    "tp_b_transfer = 0\n",
    "fp_b_transfer = 0\n",
    "tn_b_transfer = 0\n",
    "fn_b_transfer = 0\n",
    "preds_b_transfer = [math.exp(preds_b_transfer[i][1])/(math.exp(preds_b_transfer[i][0]) + math.exp(preds_b_transfer[i][1])) for i in range(len(preds_e))]\n",
    "for i in range(len(preds_b_transfer)):\n",
    "    if acts_b_transfer[i] == 1:\n",
    "        if preds_b_transfer[i] >= 0.5:\n",
    "            tp_b_transfer += 1\n",
    "        else:\n",
    "            fn_b_transfer += 1\n",
    "    else:\n",
    "        if preds_b_transfer[i] < 0.5:\n",
    "            tn_b_transfer += 1\n",
    "        else:\n",
    "            fp_b_transfer += 1\n",
    "accuracy_b_transfer = (tp_b_transfer + tn_b_transfer)/(tp_b_transfer + fp_b_transfer + fn_b_transfer + tn_b_transfer)\n",
    "recall_b_transfer = tp_b_transfer/(tp_b_transfer + fn_b_transfer)\n",
    "precision_b_transfer = tp_b_transfer/(tp_b_transfer + fp_b_transfer)\n",
    "f1_b_transfer = (2*precision_b_transfer*recall_b_transfer)/(precision_b_transfer + recall_b_transfer)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_b_transfer, fp_b_transfer, fn_b_transfer, tn_b_transfer))\n",
    "print(\"Recall:\", recall_b_transfer)\n",
    "print(\"Precsion:\", precision_b_transfer)\n",
    "print(\"F1:\", f1_b_transfer)\n",
    "print(\"Accuracy\", accuracy_b_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 96, FP: 23\n",
      "FN: 127, TN: 116\n",
      "Recall: 0.4304932735426009\n",
      "Precsion: 0.8067226890756303\n",
      "F1: 0.5614035087719298\n",
      "Accuracy 0.585635359116022\n"
     ]
    }
   ],
   "source": [
    "#CLASS C: Transfer learning from hateval\n",
    "\n",
    "tp_c_transfer = 0\n",
    "fp_c_transfer = 0\n",
    "tn_c_transfer = 0\n",
    "fn_c_transfer = 0\n",
    "preds_c_transfer = [math.exp(preds_c_transfer[i][1])/(math.exp(preds_c_transfer[i][0]) + math.exp(preds_c_transfer[i][1])) for i in range(len(preds_e))]\n",
    "for i in range(len(preds_c_transfer)):\n",
    "    if acts_c_transfer[i] == 1:\n",
    "        if preds_c_transfer[i] >= 0.5:\n",
    "            tp_c_transfer += 1\n",
    "        else:\n",
    "            fn_c_transfer += 1\n",
    "    else:\n",
    "        if preds_c_transfer[i] < 0.5:\n",
    "            tn_c_transfer += 1\n",
    "        else:\n",
    "            fp_c_transfer += 1\n",
    "accuracy_c_transfer = (tp_c_transfer + tn_c_transfer)/(tp_c_transfer + fp_c_transfer + fn_c_transfer + tn_c_transfer)\n",
    "recall_c_transfer = tp_c_transfer/(tp_c_transfer + fn_c_transfer)\n",
    "precision_c_transfer = tp_c_transfer/(tp_c_transfer + fp_c_transfer)\n",
    "f1_c_transfer = (2*precision_c_transfer*recall_c_transfer)/(precision_c_transfer + recall_c_transfer)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_c_transfer, fp_c_transfer, fn_c_transfer, tn_c_transfer))\n",
    "print(\"Recall:\", recall_c_transfer)\n",
    "print(\"Precsion:\", precision_c_transfer)\n",
    "print(\"F1:\", f1_c_transfer)\n",
    "print(\"Accuracy\", accuracy_c_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 12, FP: 107\n",
      "FN: 91, TN: 152\n",
      "Recall: 0.11650485436893204\n",
      "Precsion: 0.10084033613445378\n",
      "F1: 0.10810810810810811\n",
      "Accuracy 0.4530386740331492\n"
     ]
    }
   ],
   "source": [
    "#CLASS D: Transfer learning from hateval\n",
    "\n",
    "tp_d_transfer = 0\n",
    "fp_d_transfer = 0\n",
    "tn_d_transfer = 0\n",
    "fn_d_transfer = 0\n",
    "preds_d_transfer = [math.exp(preds_d_transfer[i][1])/(math.exp(preds_d_transfer[i][0]) + math.exp(preds_d_transfer[i][1])) for i in range(len(preds_e))]\n",
    "for i in range(len(preds_d_transfer)):\n",
    "    if acts_d_transfer[i] == 1:\n",
    "        if preds_d_transfer[i] >= 0.5:\n",
    "            tp_d_transfer += 1\n",
    "        else:\n",
    "            fn_d_transfer += 1\n",
    "    else:\n",
    "        if preds_d_transfer[i] < 0.5:\n",
    "            tn_d_transfer += 1\n",
    "        else:\n",
    "            fp_d_transfer += 1\n",
    "accuracy_d_transfer = (tp_d_transfer + tn_d_transfer)/(tp_d_transfer + fp_d_transfer + fn_d_transfer + tn_d_transfer)\n",
    "recall_d_transfer = tp_d_transfer/(tp_d_transfer + fn_d_transfer)\n",
    "precision_d_transfer = tp_d_transfer/(tp_d_transfer + fp_d_transfer)\n",
    "f1_d_transfer = (2*precision_d_transfer*recall_d_transfer)/(precision_d_transfer + recall_d_transfer)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_d_transfer, fp_d_transfer, fn_d_transfer, tn_d_transfer))\n",
    "print(\"Recall:\", recall_d_transfer)\n",
    "print(\"Precsion:\", precision_d_transfer)\n",
    "print(\"F1:\", f1_d_transfer)\n",
    "print(\"Accuracy\", accuracy_d_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 3, FP: 107\n",
      "FN: 29, TN: 223\n",
      "Recall: 0.09375\n",
      "Precsion: 0.02727272727272727\n",
      "F1: 0.04225352112676056\n",
      "Accuracy 0.6243093922651933\n"
     ]
    }
   ],
   "source": [
    "#CLASS D: Transfer learning from hateval\n",
    "\n",
    "tp_e_transfer = 0\n",
    "fp_e_transfer = 0\n",
    "tn_e_transfer = 0\n",
    "fn_e_transfer = 0\n",
    "preds_e_transfer = [math.exp(preds_e_transfer[i][1])/(math.exp(preds_e_transfer[i][0]) + math.exp(preds_e_transfer[i][1])) for i in range(len(preds_e))]\n",
    "for i in range(len(preds_e_transfer)):\n",
    "    if acts_e_transfer[i] == 1:\n",
    "        if preds_e_transfer[i] >= 0.5:\n",
    "            tp_e_transfer += 1\n",
    "        else:\n",
    "            fn_e_transfer += 1\n",
    "    else:\n",
    "        if preds_e_transfer[i] < 0.5:\n",
    "            tn_e_transfer += 1\n",
    "        else:\n",
    "            fp_e_transfer += 1\n",
    "accuracy_e_transfer = (tp_e_transfer + tn_e_transfer)/(tp_e_transfer + fp_e_transfer + fn_e_transfer + tn_e_transfer)\n",
    "recall_e_transfer = tp_e_transfer/(tp_e_transfer + fn_e_transfer)\n",
    "precision_e_transfer = tp_e_transfer/(tp_e_transfer + fp_e_transfer)\n",
    "f1_e_transfer = (2*precision_e_transfer*recall_e_transfer)/(precision_e_transfer + recall_e_transfer)\n",
    "print(\"TP: {}, FP: {}\\nFN: {}, TN: {}\".format(tp_e_transfer, fp_e_transfer, fn_e_transfer, tn_e_transfer))\n",
    "print(\"Recall:\", recall_e_transfer)\n",
    "print(\"Precsion:\", precision_e_transfer)\n",
    "print(\"F1:\", f1_e_transfer)\n",
    "print(\"Accuracy\", accuracy_e_transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro average F1 for class 3 IND/GRP/OTH is 0.23725504600226613\n",
      "Macro average F1 overall 0.3816405787072135\n"
     ]
    }
   ],
   "source": [
    "#overall results for transfer learning from hateval\n",
    "\n",
    "f1_3_transfer = (f1_c_transfer + f1_d_transfer + f1_e_transfer)/3\n",
    "print(\"Macro average F1 for class 3 IND/GRP/OTH is\", f1_3_transfer)\n",
    "print(\"Macro average F1 overall\", (f1_a_transfer + f1_b_transfer + f1_3_transfer)/3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sentence Entailment BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0183e10141f049a1820827c9dfbd6c5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d01f56954ef74452b649def7b9adc937",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a4784a513b749d68959b4250a8a1593",
      "value": 28
     }
    },
    "0504a8ce7be543a49611a424fcfc9ca7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1543919f31dd46c6a967a412af4d21bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16b6fa8b34e24eedb7c6c80e9e57b5d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "24f1399337dc4cf998e189d697b8e282": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e8aaf8e2a644b8384d07e86578e7624": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30c1af9f395f4f148a4038c1f13b2088": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7e7c6e812fdc4b36a25096e9f176f75a",
       "IPY_MODEL_bf7f2daca2264bd289670898d7ab10e4",
       "IPY_MODEL_3af999385a094ccc85eadf702ab69723"
      ],
      "layout": "IPY_MODEL_1543919f31dd46c6a967a412af4d21bd"
     }
    },
    "322cc0d27aea4458a9efe1c099943482": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0d781c1aae342ae949264fb561b7f5f",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_677cf9fc8f3d47c68e73bd4a3622132b",
      "value": 466062
     }
    },
    "373af73466be45f1bb216e6abbdb15be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3af999385a094ccc85eadf702ab69723": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e50074e3a054225842a6fe8ef936183",
      "placeholder": "​",
      "style": "IPY_MODEL_c2496080cc384158856247dd5581e751",
      "value": " 570/570 [00:00&lt;00:00, 13.4kB/s]"
     }
    },
    "3e50074e3a054225842a6fe8ef936183": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "405ea21b2692487298e89e719c6573b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd90fde29e26447c9eaeef9aaf15d01f",
      "placeholder": "​",
      "style": "IPY_MODEL_16b6fa8b34e24eedb7c6c80e9e57b5d2",
      "value": "Downloading: 100%"
     }
    },
    "41fe1073e1ea44669cdbef98949f9528": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43f942f812884ace90aa9b1dd41a3d9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "45dcdc23c9b4481a9e40878e4dbfd585": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2a5689111c3420c9ed4114bb55cf0fc",
      "placeholder": "​",
      "style": "IPY_MODEL_d09c0639c5ef45a7823074eb648de6d7",
      "value": "Downloading: 100%"
     }
    },
    "4720c540eecc4dbe8fee8c9596f56933": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "546361d1061243f5b7fc5692b1c9d4c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d80c6db4dfc4bf0aaea82350dffdc21": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "602d9b5979084873996eab9784b98edc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6497737147ce458b881bbb1b17492364": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "677cf9fc8f3d47c68e73bd4a3622132b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6b127ca5fb5a4d23b6c3ffe654cdfcaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c0f5454779b4baeafa828e961459116": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a39de3d6df814e98be1a65e049bff39e",
       "IPY_MODEL_ef706620a1e34c3a84de18a03a85f8cd",
       "IPY_MODEL_bfee36d5b72d469cb308f4007e1474a0"
      ],
      "layout": "IPY_MODEL_f17b3761a665477e8fdecfd23d267f87"
     }
    },
    "6f61782328964e4dbdea05bee3797ee9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb792d8fbadc4bb6977a1986a9783e15",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b127ca5fb5a4d23b6c3ffe654cdfcaf",
      "value": 440473133
     }
    },
    "7e7c6e812fdc4b36a25096e9f176f75a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e8aaf8e2a644b8384d07e86578e7624",
      "placeholder": "​",
      "style": "IPY_MODEL_d84069b7b1384beaa5100505f9233b2b",
      "value": "Downloading: 100%"
     }
    },
    "814534237a9144deb7d52e4ceffabc43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6497737147ce458b881bbb1b17492364",
      "placeholder": "​",
      "style": "IPY_MODEL_373af73466be45f1bb216e6abbdb15be",
      "value": " 420M/420M [00:10&lt;00:00, 36.1MB/s]"
     }
    },
    "8665ae01129141dfb7fdf5037a994c86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93f0f8c7257944e6ab97295f09821f1d",
      "placeholder": "​",
      "style": "IPY_MODEL_a61965e1ea50438c868778deb83db312",
      "value": " 28.0/28.0 [00:00&lt;00:00, 518B/s]"
     }
    },
    "89a7fc4f932041a7b76b2502096ede49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8a4784a513b749d68959b4250a8a1593": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "93ded7574b56441eaa9b6aaaa30840f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93f0f8c7257944e6ab97295f09821f1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95d0e5c35a01408fa9bde956d0785d21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_405ea21b2692487298e89e719c6573b0",
       "IPY_MODEL_0183e10141f049a1820827c9dfbd6c5a",
       "IPY_MODEL_8665ae01129141dfb7fdf5037a994c86"
      ],
      "layout": "IPY_MODEL_93ded7574b56441eaa9b6aaaa30840f3"
     }
    },
    "9d383d03f9304bce914326ea0e5d472b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a39de3d6df814e98be1a65e049bff39e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24f1399337dc4cf998e189d697b8e282",
      "placeholder": "​",
      "style": "IPY_MODEL_f3dea62699df437c945160dfc42afbd5",
      "value": "Downloading: 100%"
     }
    },
    "a61965e1ea50438c868778deb83db312": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf065a9136dc4262a74c04f746b7c143": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d383d03f9304bce914326ea0e5d472b",
      "placeholder": "​",
      "style": "IPY_MODEL_43f942f812884ace90aa9b1dd41a3d9a",
      "value": "Downloading: 100%"
     }
    },
    "bf7f2daca2264bd289670898d7ab10e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d80c6db4dfc4bf0aaea82350dffdc21",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89a7fc4f932041a7b76b2502096ede49",
      "value": 570
     }
    },
    "bfee36d5b72d469cb308f4007e1474a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcde074381814577a68122dd6e5adf30",
      "placeholder": "​",
      "style": "IPY_MODEL_4720c540eecc4dbe8fee8c9596f56933",
      "value": " 226k/226k [00:00&lt;00:00, 215kB/s]"
     }
    },
    "c2496080cc384158856247dd5581e751": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c38a9f17f85544b68ffdc8e501a95f20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45dcdc23c9b4481a9e40878e4dbfd585",
       "IPY_MODEL_322cc0d27aea4458a9efe1c099943482",
       "IPY_MODEL_e4669478d1474c4485c45907447d75a5"
      ],
      "layout": "IPY_MODEL_41fe1073e1ea44669cdbef98949f9528"
     }
    },
    "d01f56954ef74452b649def7b9adc937": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d09c0639c5ef45a7823074eb648de6d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d84069b7b1384beaa5100505f9233b2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dcde074381814577a68122dd6e5adf30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd90fde29e26447c9eaeef9aaf15d01f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0c07e3c6bd042c2a3dd2aed325f6759": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0d781c1aae342ae949264fb561b7f5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4669478d1474c4485c45907447d75a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_546361d1061243f5b7fc5692b1c9d4c5",
      "placeholder": "​",
      "style": "IPY_MODEL_602d9b5979084873996eab9784b98edc",
      "value": " 455k/455k [00:00&lt;00:00, 691kB/s]"
     }
    },
    "e8a66bb5d7614602ac93db9cac811135": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf065a9136dc4262a74c04f746b7c143",
       "IPY_MODEL_6f61782328964e4dbdea05bee3797ee9",
       "IPY_MODEL_814534237a9144deb7d52e4ceffabc43"
      ],
      "layout": "IPY_MODEL_0504a8ce7be543a49611a424fcfc9ca7"
     }
    },
    "ef706620a1e34c3a84de18a03a85f8cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0c07e3c6bd042c2a3dd2aed325f6759",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff8facd357854c18976dea8f1621cae6",
      "value": 231508
     }
    },
    "f17b3761a665477e8fdecfd23d267f87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2a5689111c3420c9ed4114bb55cf0fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3dea62699df437c945160dfc42afbd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb792d8fbadc4bb6977a1986a9783e15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff8facd357854c18976dea8f1621cae6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
